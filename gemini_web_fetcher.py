#!/usr/bin/env python3
"""
Gemini APIã‚’ä½¿ç”¨ã—ã¦Webã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚„403ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã‚½ãƒ¼ã‚¹ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
"""
import os
import time
import json
import requests
from typing import List, Dict, Optional
from gemini_analyzer import GeminiAnalyzer

class GeminiWebFetcher:
    def __init__(self):
        """Gemini Web FetcheråˆæœŸåŒ–"""
        self.analyzer = GeminiAnalyzer()
        self.session = requests.Session()
        
    def fetch_from_problematic_source(self, url: str, source_name: str) -> List[Dict]:
        """
        403ã‚¨ãƒ©ãƒ¼ãªã©ã‚¢ã‚¯ã‚»ã‚¹å›°é›£ãªã‚½ãƒ¼ã‚¹ã‹ã‚‰Gemini APIã§æƒ…å ±å–å¾—
        
        Args:
            url: å–å¾—ã—ãŸã„URL (ä¾‹: Google Newsã®RSS)
            source_name: ã‚½ãƒ¼ã‚¹å
            
        Returns:
            ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã®ãƒªã‚¹ãƒˆ
        """
        if not self.analyzer.enabled:
            print(f"âš ï¸ Gemini API not available for {source_name}")
            return []
        
        print(f"ğŸ¤– Gemini APIã§{source_name}ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
        
        # Geminiã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ç”Ÿæˆã‚’ä¾é ¼
        prompt = f"""
ã‚ãªãŸã¯AIæ¥­ç•Œã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰æœ€æ–°ã®AIé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’5ä»¶ç¨‹åº¦æ•™ãˆã¦ãã ã•ã„ï¼š

ã‚½ãƒ¼ã‚¹: {source_name}
URL: {url}

ä»¥ä¸‹ã®å½¢å¼ã§JSONé…åˆ—ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ï¼š
[
  {{
    "title": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‹±èªï¼‰",
    "title_ja": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªï¼‰",
    "summary": "è¦ç´„ï¼ˆè‹±èªã€100æ–‡å­—ç¨‹åº¦ï¼‰",
    "source": "{source_name}",
    "url": "è¨˜äº‹URL",
    "importance": 1-10ã®é‡è¦åº¦ã‚¹ã‚³ã‚¢
  }}
]

æœ€æ–°ã®AIæ¥­ç•Œå‹•å‘ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’å«ã‚ã¦ãã ã•ã„ï¼š
- å¤§æ‰‹ä¼æ¥­ï¼ˆOpenAI, Google, Microsoft, Anthropicç­‰ï¼‰ã®å‹•å‘
- æ–°ã—ã„AIãƒ¢ãƒ‡ãƒ«ã‚„ãƒ„ãƒ¼ãƒ«ã®ãƒªãƒªãƒ¼ã‚¹
- æŠ•è³‡ã‚„è²·åã®ãƒ‹ãƒ¥ãƒ¼ã‚¹
- è¦åˆ¶ã‚„æ”¿ç­–ã®å‹•å‘
- æŠ€è¡“çš„ãªãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼

JSONå½¢å¼ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ã¯ä¸è¦ã§ã™ã€‚
"""
        
        response = self.analyzer._make_request(prompt)
        
        if response:
            try:
                # JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹
                import re
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    news_items = json.loads(json_match.group())
                    
                    # ç¾åœ¨æ™‚åˆ»ã‚’è¿½åŠ 
                    from datetime import datetime
                    current_time = datetime.now().strftime('%H:%M')
                    
                    for item in news_items:
                        item['time'] = current_time
                        item['_dt'] = datetime.now()
                        item['_source'] = source_name
                        item['link'] = item.get('url', '#')
                        
                    print(f"âœ… {source_name}ã‹ã‚‰{len(news_items)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—æˆåŠŸ")
                    return news_items
                    
            except Exception as e:
                print(f"[WARN] Failed to parse Gemini response for {source_name}: {e}")
        
        return []
    
    def fetch_trending_topics(self) -> List[Dict]:
        """
        Gemini APIã‚’ä½¿ã£ã¦ç¾åœ¨ã®AIæ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ãƒˆãƒ”ãƒƒã‚¯ã‚’å–å¾—
        """
        if not self.analyzer.enabled:
            return []
        
        print("ğŸ¤– Gemini APIã§æœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æä¸­...")
        
        prompt = """
AIæ¥­ç•Œã®å°‚é–€å®¶ã¨ã—ã¦ã€ä»Šæ—¥ã®æœ€ã‚‚é‡è¦ãªAIãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®å½¢å¼ã§JSONé…åˆ—ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ï¼š
[
  {
    "title": "ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè‹±èªï¼‰",
    "title_ja": "ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ—¥æœ¬èªï¼‰",
    "summary": "è©³ç´°èª¬æ˜ï¼ˆè‹±èªã€100æ–‡å­—ç¨‹åº¦ï¼‰",
    "category": "breakthrough/business/regulatory/social/technicalã®ã„ãšã‚Œã‹",
    "importance": 1-10ã®é‡è¦åº¦ã‚¹ã‚³ã‚¢,
    "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3"]
  }
]

æœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’5ã¤ç¨‹åº¦ã€é‡è¦åº¦é †ã«æ•™ãˆã¦ãã ã•ã„ã€‚
2025å¹´8æœˆã®æœ€æ–°å‹•å‘ã‚’åæ˜ ã—ã¦ãã ã•ã„ã€‚

JSONå½¢å¼ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
"""
        
        response = self.analyzer._make_request(prompt)
        
        if response:
            try:
                import re
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    trends = json.loads(json_match.group())
                    
                    from datetime import datetime
                    for trend in trends:
                        trend['source'] = 'Gemini AI Trends'
                        trend['time'] = datetime.now().strftime('%H:%M')
                        trend['_dt'] = datetime.now()
                        trend['link'] = '#'
                        
                    print(f"âœ… {len(trends)}ä»¶ã®ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—æˆåŠŸ")
                    return trends
                    
            except Exception as e:
                print(f"[WARN] Failed to parse trending topics: {e}")
        
        return []
    
    def supplement_403_sources(self, failed_sources: List[str]) -> Dict[str, List[Dict]]:
        """
        403ã‚¨ãƒ©ãƒ¼ã«ãªã£ãŸã‚½ãƒ¼ã‚¹ã®ä»£æ›¿æƒ…å ±ã‚’Gemini APIã§è£œå®Œ
        
        Args:
            failed_sources: å¤±æ•—ã—ãŸã‚½ãƒ¼ã‚¹ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            ã‚½ãƒ¼ã‚¹åã‚’ã‚­ãƒ¼ã¨ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹è¾æ›¸
        """
        supplemented_data = {}
        
        if not self.analyzer.enabled:
            return supplemented_data
        
        for source in failed_sources:
            if '403' in source or 'Google News' in source:
                # Google Newsãªã©å•é¡Œã®ã‚ã‚‹ã‚½ãƒ¼ã‚¹ã‚’ç‰¹å®š
                if 'Google News' in source:
                    # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ã¦ç•°ãªã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
                    if 'AIä¼æ¥­ãƒ»æŠ•è³‡' in source or 'æ—¥æœ¬' in source:
                        news = self.fetch_from_problematic_source(
                            url='https://news.google.com/topics/ai',
                            source_name='Google News AI (Geminiè£œå®Œ)'
                        )
                    elif 'AIãƒ„ãƒ¼ãƒ«' in source:
                        news = self.fetch_from_problematic_source(
                            url='https://news.google.com/topics/ai-tools',
                            source_name='Google News Tools (Geminiè£œå®Œ)'
                        )
                    else:
                        news = self.fetch_from_problematic_source(
                            url='https://news.google.com/topics/ai-research',
                            source_name='Google News Research (Geminiè£œå®Œ)'
                        )
                    
                    if news:
                        supplemented_data[source] = news
        
        return supplemented_data

def integrate_with_build_py():
    """
    build.pyã‚„generate_comprehensive_dashboard.pyã«çµ±åˆã™ã‚‹ãŸã‚ã®é–¢æ•°
    """
    fetcher = GeminiWebFetcher()
    
    # 403ã‚¨ãƒ©ãƒ¼ã‚½ãƒ¼ã‚¹ã®ä»£æ›¿ãƒ‡ãƒ¼ã‚¿å–å¾—
    failed_sources = [
        'Google News: AIä¼æ¥­ãƒ»æŠ•è³‡ (æ—¥æœ¬èª)',
        'Google News: AIãƒ„ãƒ¼ãƒ«ãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯',
        'Google News: AIè«–æ–‡ãƒ»ç ”ç©¶'
    ]
    
    supplemented = fetcher.supplement_403_sources(failed_sources)
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚‚å–å¾—
    trends = fetcher.fetch_trending_topics()
    
    return supplemented, trends

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    from dotenv import load_dotenv
    load_dotenv()
    
    fetcher = GeminiWebFetcher()
    
    if fetcher.analyzer.enabled:
        print("\nğŸ“Š 403ã‚¨ãƒ©ãƒ¼ã‚½ãƒ¼ã‚¹ã®ä»£æ›¿å–å¾—ãƒ†ã‚¹ãƒˆ...")
        
        # Google Newsã®ä»£æ›¿ã‚’å–å¾—
        news = fetcher.fetch_from_problematic_source(
            url='https://news.google.com/rss/topics/ai',
            source_name='Google News AI'
        )
        
        if news:
            print(f"\nâœ… å–å¾—æˆåŠŸ: {len(news)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹")
            for item in news[:3]:
                print(f"  - {item['title_ja'][:50]}...")
                print(f"    é‡è¦åº¦: {item.get('importance', 0)}")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ãƒ†ã‚¹ãƒˆ
        print("\nğŸ”¥ ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ãƒ†ã‚¹ãƒˆ...")
        trends = fetcher.fetch_trending_topics()
        
        if trends:
            print(f"\nâœ… ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—æˆåŠŸ: {len(trends)}ä»¶")
            for trend in trends[:3]:
                print(f"  - {trend['title_ja'][:50]}...")
                print(f"    ã‚«ãƒ†ã‚´ãƒª: {trend.get('category', 'N/A')}")
    else:
        print("âŒ Gemini APIãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")