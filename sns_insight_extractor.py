#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
X(Twitter)æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ‰ç›Šãªæƒ…å ±ã‚’æŠ½å‡ºãƒ»åˆ†æ
"""

import os
import sys
import json
import csv
import io
import requests
import re
from datetime import datetime, timedelta
from collections import defaultdict
from typing import List, Dict, Any, Tuple
import warnings

# è­¦å‘Šç„¡åŠ¹åŒ–
warnings.filterwarnings('ignore')

# è¨­å®š
CSV_URL = 'https://docs.google.com/spreadsheets/d/1uuLKCLIJw--a1vCcO6UGxSpBiLTtN8uGl2cdMb6wcfg/export?format=csv&gid=0'
TARGET_HOURS = 48

class SNSInsightExtractor:
    """SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºå™¨"""
    
    def __init__(self, mode: str = "lenient"):
        """
        mode: "strict" ã¾ãŸã¯ "lenient"
        strict: 48æ™‚é–“ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç©ºçµæœ
        lenient: ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æœ€æ–°ã‹ã‚‰48æ™‚é–“ã§å†æŠ½å‡º
        """
        self.mode = mode
        self.now_jst = datetime.now()
        self.cutoff_time = self.now_jst - timedelta(hours=TARGET_HOURS)
    
    def fetch_csv_data(self) -> List[Dict]:
        """CSVãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        print("ğŸ“± SNSæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        try:
            response = requests.get(CSV_URL, timeout=30)
            response.raise_for_status()
            
            # BOMå¯¾å¿œã®CSVè§£æï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã®CSVã¨ã—ã¦å‡¦ç†ï¼‰
            csv_content = response.content.decode('utf-8-sig')
            csv_reader = csv.reader(io.StringIO(csv_content))
            
            posts = []
            for i, row in enumerate(csv_reader):
                if len(row) < 4:  # æœ€ä½é™ã®ã‚«ãƒ©ãƒ æ•°ãƒã‚§ãƒƒã‚¯
                    continue
                    
                # ä½ç½®ãƒ™ãƒ¼ã‚¹ã§ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                post_data = {
                    'timestamp': row[0] if len(row) > 0 else '',
                    'username': row[1] if len(row) > 1 else '',
                    'text': row[2] if len(row) > 2 else '',
                    'image_url': row[3] if len(row) > 3 else '',
                    'post_url': row[4] if len(row) > 4 else ''
                }
                
                posts.append(post_data)
                
                # æœ€åˆã®5è¡Œã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±
                if i < 5:
                    print(f"[DEBUG] Row {i}: timestamp='{post_data['timestamp'][:30]}...', username='{post_data['username']}', text='{post_data['text'][:50]}...'")
            
            print(f"âœ… CSVå–å¾—å®Œäº†: {len(posts)}è¡Œ")
            return posts
            
        except Exception as e:
            print(f"[ERROR] CSVå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def normalize_posts(self, posts: List[Dict]) -> List[Dict]:
        """æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–"""
        print("ğŸ”„ æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ä¸­...")
        
        normalized = []
        skipped_count = 0
        
        for i, post in enumerate(posts):
            try:
                # æ—¥æ™‚æŠ½å‡º
                timestamp = self._extract_timestamp(post)
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼åæŠ½å‡º
                username = self._extract_username(post)
                
                # æœ¬æ–‡æŠ½å‡º
                text = self._extract_text(post)
                
                # URLæŠ½å‡º
                url = self._extract_url(post)
                
                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆæœ€åˆã®5è¡Œï¼‰
                if i < 5:
                    print(f"[DEBUG] Post {i}: text='{text[:50] if text else 'None'}', username='{username}', timestamp='{timestamp}'")
                
                if not text or len(text) < 10:
                    skipped_count += 1
                    if i < 5:
                        print(f"[DEBUG] Skipped post {i}: text too short or empty")
                    continue
                
                normalized_post = {
                    'timestamp': timestamp,
                    'timestamp_str': timestamp.isoformat() if timestamp else '',
                    'username': username,
                    'text': text,
                    'url': url,
                    'original_data': post
                }
                
                normalized.append(normalized_post)
                
            except Exception as e:
                if i < 5:
                    print(f"[DEBUG] Error processing post {i}: {e}")
                continue
        
        print(f"âœ… æ­£è¦åŒ–å®Œäº†: {len(normalized)}ä»¶ (ã‚¹ã‚­ãƒƒãƒ—: {skipped_count}ä»¶)")
        return normalized
    
    def _extract_timestamp(self, post: Dict) -> datetime:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æŠ½å‡ºãƒ»å¤‰æ›"""
        timestamp_fields = ['timestamp', 'date', 'created_at', 'time', 'datetime']
        
        for field in timestamp_fields:
            if field in post and post[field]:
                timestamp_str = post[field].strip()
                if timestamp_str:
                    return self._parse_timestamp(timestamp_str)
        
        return None
    
    def _parse_timestamp(self, timestamp_str: str) -> datetime:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ–‡å­—åˆ—ã‚’datetimeã«å¤‰æ›ï¼ˆJSTæƒ³å®šï¼‰"""
        # æ—¢å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        formats = [
            '%Y-%m-%d %H:%M:%S',
            '%Y-%m-%dT%H:%M:%S',
            '%Y-%m-%d',
            '%m/%d/%Y %H:%M:%S',
            '%m/%d/%Y',
            '%d/%m/%Y %H:%M:%S',
            '%d/%m/%Y',
            '%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S',
            '%Yå¹´%mæœˆ%dæ—¥'
        ]
        
        # Xç‰¹æœ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ "August 10, 2025 at 02:41AM" ã‚’å‡¦ç†
        if ' at ' in timestamp_str:
            try:
                # "August 10, 2025 at 02:41AM" -> "August 10, 2025 02:41AM"
                clean_timestamp = timestamp_str.replace(' at ', ' ')
                return datetime.strptime(clean_timestamp, '%B %d, %Y %I:%M%p')
            except ValueError:
                pass
        
        for fmt in formats:
            try:
                # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚„ç§’æ•°ä»¥ä¸‹ã‚’é™¤å»
                clean_timestamp = timestamp_str.split('.')[0].split('+')[0].split('Z')[0]
                return datetime.strptime(clean_timestamp, fmt)
            except ValueError:
                continue
        
        # ãƒ‘ãƒ¼ã‚¹ã§ããªã„å ´åˆã¯ç¾åœ¨æ™‚åˆ»
        return datetime.now()
    
    def _extract_username(self, post: Dict) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼åæŠ½å‡º"""
        username_fields = ['username', 'user', 'author', 'screen_name', 'account']
        
        for field in username_fields:
            if field in post and post[field]:
                username = post[field].strip()
                if username:
                    # @ãƒãƒ¼ã‚¯ã‚’è¿½åŠ ï¼ˆãªã„å ´åˆï¼‰
                    return username if username.startswith('@') else f"@{username}"
        
        return "@unknown"
    
    def _extract_text(self, post: Dict) -> str:
        """æœ¬æ–‡æŠ½å‡º"""
        text_fields = ['text', 'content', 'tweet_text', 'message', 'post', 'body']
        
        for field in text_fields:
            if field in post and post[field]:
                text = post[field].strip()
                if text:
                    return text
        
        return ""
    
    def _extract_url(self, post: Dict) -> str:
        """URLæŠ½å‡ºï¼ˆæœ€åˆã®X URLï¼‰"""
        url_fields = ['post_url', 'url', 'x_url', 'tweet_url', 'link']
        
        for field in url_fields:
            if field in post and post[field]:
                url = post[field].strip()
                if url and ('x.com' in url or 'twitter.com' in url):
                    # twitter.com ã‚’ x.com ã«æ­£è¦åŒ–
                    return url.replace('twitter.com', 'x.com')
        
        return ""
    
    def filter_48h(self, posts: List[Dict]) -> Tuple[List[Dict], str]:
        """48æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        print(f"ğŸ•’ 48æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä¸­ï¼ˆåŸºæº–: {self.cutoff_time.strftime('%Y-%m-%d %H:%M:%S')}ï¼‰...")
        
        filtered = []
        last_timestamp = None
        
        for post in posts:
            timestamp = post['timestamp']
            if timestamp:
                if timestamp >= self.cutoff_time:
                    filtered.append(post)
                
                # æœ€æ–°ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¨˜éŒ²
                if last_timestamp is None or timestamp > last_timestamp:
                    last_timestamp = timestamp
        
        if not filtered and self.mode == "lenient" and last_timestamp:
            print("âš ï¸ 48æ™‚é–“ä»¥å†…ã®ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚lenientãƒ¢ãƒ¼ãƒ‰ã§å†æŠ½å‡º...")
            # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰48æ™‚é–“ã§å†è¨ˆç®—
            new_cutoff = last_timestamp - timedelta(hours=TARGET_HOURS)
            for post in posts:
                timestamp = post['timestamp']
                if timestamp and timestamp >= new_cutoff:
                    filtered.append(post)
            
            filter_mode = f"lenient (æœ€æ–°: {last_timestamp.strftime('%Y-%m-%d %H:%M:%S')})"
        else:
            filter_mode = "strict"
        
        print(f"âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Œäº†: {len(filtered)}ä»¶ (ãƒ¢ãƒ¼ãƒ‰: {filter_mode})")
        return filtered, filter_mode
    
    def calculate_score(self, post: Dict) -> float:
        """æœ‰ç›Šåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆ0-10ï¼‰"""
        text = post['text'].lower()
        username = post['username'].lower()
        timestamp = post['timestamp']
        
        score = 0.0
        
        # ãƒ†ãƒ¼ãƒä¸€è‡´åº¦ï¼ˆ0-4ç‚¹ï¼‰
        theme_keywords = {
            'release': ['release', 'released', 'launching', 'launch', 'å…¬é–‹', 'ãƒªãƒªãƒ¼ã‚¹', 'announced'],
            'funding': ['funding', 'raised', 'investment', 'ipo', 'è³‡é‡‘èª¿é”', 'æŠ•è³‡', 'series'],
            'partnership': ['partnership', 'collaboration', 'acquisition', 'ææº', 'è²·å', 'merger'],
            'hiring': ['hiring', 'join', 'team', 'æ¡ç”¨', 'å…¥ç¤¾', 'welcome'],
            'research': ['paper', 'research', 'benchmark', 'è«–æ–‡', 'ç ”ç©¶', 'study'],
            'official': ['announcing', 'excited to', 'proud to', 'ç™ºè¡¨', 'official']
        }
        
        theme_matches = 0
        for theme, keywords in theme_keywords.items():
            if any(keyword in text for keyword in keywords):
                theme_matches += 1
        
        score += min(3.5, theme_matches * 1.0)  # ãƒ†ãƒ¼ãƒãƒãƒƒãƒã‚’ç·©å’Œ
        
        # å…·ä½“æ€§ï¼ˆ0-2.5ç‚¹ï¼‰
        specificity = 0
        
        # é‡‘é¡ãƒ»æ•°å€¤
        if re.search(r'\$\d+[MBK]|\d+å„„|\d+ä¸‡|Â¥\d+|\d+%', text):
            specificity += 1
        
        # æ—¥ä»˜
        if re.search(r'\d{4}-\d{2}-\d{2}|\d{1,2}/\d{1,2}|\d{1,2}æœˆ', text):
            specificity += 0.5
        
        # URLãƒ»è£½å“å
        if re.search(r'http[s]?://\S+|\.com|\.ai|v\d+\.\d+', text):
            specificity += 0.5
        
        # AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        if re.search(r'AI|GPT|LLM|æ©Ÿæ¢°å­¦ç¿’|äººå·¥çŸ¥èƒ½|ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°', text, re.IGNORECASE):
            specificity += 1
        
        score += min(2.5, specificity)
        
        # ç™ºä¿¡å…ƒä¿¡é ¼æ€§ï¼ˆ0-2ç‚¹ï¼‰
        trusted_indicators = ['openai', 'anthropic', 'google', 'microsoft', 'meta', 'nvidia', 'official']
        if any(indicator in username for indicator in trusted_indicators):
            score += 2.0
        elif len(username) > 4:  # å®Ÿåœ¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ
            score += 1.5  # åŸºæº–å€¤ä¸Šã’
        
        # é®®åº¦ãƒœãƒ¼ãƒŠã‚¹ï¼ˆ0-1.5ç‚¹ï¼‰
        if timestamp:
            hours_ago = (self.now_jst - timestamp).total_seconds() / 3600
            if hours_ago <= 12:
                score += 1.5  # 12æ™‚é–“ä»¥å†…ã¯ãƒœãƒ¼ãƒŠã‚¹å¢—
            elif hours_ago <= 24:
                score += 1.0
            elif hours_ago <= 48:
                score += 0.5
        
        # åŸºæœ¬ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢ï¼ˆå­˜åœ¨ã™ã‚‹ã ã‘ã§0.5ç‚¹ï¼‰
        score += 0.5
        
        return min(10.0, score)
    
    def filter_useful_posts(self, posts: List[Dict]) -> List[Dict]:
        """æœ‰ç›ŠæŠ•ç¨¿ã®æŠ½å‡º"""
        print("ğŸ¯ æœ‰ç›ŠæŠ•ç¨¿ã‚’æŠ½å‡ºä¸­...")
        
        scored_posts = []
        
        for post in posts:
            score = self.calculate_score(post)
            post['score'] = score
            scored_posts.append(post)
        
        # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
        scored_posts.sort(key=lambda x: x['score'], reverse=True)
        
        # å‹•çš„ã—ãã„å€¤è¨­å®šï¼š1æ—¥10-15ä»¶ç¨‹åº¦ã‚’ç›®æ¨™
        target_count = min(15, max(10, len(scored_posts) // 10))  # æœ€ä½10ä»¶ã€æœ€å¤§15ä»¶
        
        if len(scored_posts) >= target_count:
            # ä¸Šä½Nä»¶ã‚’é¸æŠ
            useful_posts = scored_posts[:target_count]
            min_score = useful_posts[-1]['score']
            print(f"âœ… æœ‰ç›ŠæŠ•ç¨¿æŠ½å‡ºå®Œäº†: {len(useful_posts)}ä»¶ (ä¸Šä½{target_count}ä»¶ã€æœ€ä½ã‚¹ã‚³ã‚¢: {min_score:.1f})")
        else:
            # å…¨ä»¶ãŒã‚¹ã‚³ã‚¢3.0ä»¥ä¸Šã®å ´åˆã¯æ¡ç”¨
            useful_posts = [post for post in scored_posts if post['score'] >= 3.0]
            print(f"âœ… æœ‰ç›ŠæŠ•ç¨¿æŠ½å‡ºå®Œäº†: {len(useful_posts)}ä»¶ (ã‚¹ã‚³ã‚¢3.0ä»¥ä¸Š)")
        
        return useful_posts
    
    def generate_japanese_title(self, text: str) -> str:
        """æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆ14å­—å‰å¾Œï¼‰"""
        # è‹±èªæŠ•ç¨¿ã®å ´åˆã¯ç°¡æ˜“ç¿»è¨³ãƒ»è¦ç´„
        text_clean = re.sub(r'http[s]?://\S+', '', text).strip()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ç°¡æ˜“è¦ç´„
        if 'release' in text.lower() or 'launch' in text.lower():
            if 'ai' in text.lower():
                return "AIæ–°è£½å“ãƒªãƒªãƒ¼ã‚¹ç™ºè¡¨"
            return "æ–°è£½å“ãƒªãƒªãƒ¼ã‚¹ç™ºè¡¨"
        
        elif 'funding' in text.lower() or 'raised' in text.lower():
            return "è³‡é‡‘èª¿é”ãƒ‹ãƒ¥ãƒ¼ã‚¹"
        
        elif 'partnership' in text.lower() or 'collaboration' in text.lower():
            return "æˆ¦ç•¥çš„ææºç™ºè¡¨"
        
        elif 'research' in text.lower() or 'paper' in text.lower():
            return "AIç ”ç©¶æˆæœç™ºè¡¨"
        
        elif 'hiring' in text.lower() or 'join' in text.lower():
            return "äººææ¡ç”¨ãƒ»çµ„ç¹”æ‹¡å¤§"
        
        else:
            # æœ€åˆã®50æ–‡å­—ã‚’ä½¿ç”¨
            if len(text_clean) > 14:
                return text_clean[:14] + "..."
            return text_clean
    
    def categorize_post(self, post: Dict) -> str:
        """æŠ•ç¨¿ã®ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
        text = post['text'].lower()
        
        if any(kw in text for kw in ['release', 'launch', 'product', 'æ–°è£½å“', 'ãƒªãƒªãƒ¼ã‚¹']):
            return 'new_products'
        elif any(kw in text for kw in ['funding', 'investment', 'raised', 'è³‡é‡‘èª¿é”']):
            return 'funding'
        elif any(kw in text for kw in ['partnership', 'hiring', 'join', 'ææº', 'æ¡ç”¨']):
            return 'partnership_hiring'
        elif any(kw in text for kw in ['research', 'paper', 'study', 'ç ”ç©¶', 'è«–æ–‡']):
            return 'research'
        elif any(kw in text for kw in ['regulation', 'policy', 'law', 'è¦åˆ¶', 'æ”¿ç­–']):
            return 'regulation'
        else:
            return 'community'
    
    def generate_html_report(self, posts: List[Dict], filter_mode: str, 
                           total_rows: int, filtered_48h: int) -> str:
        """HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        if not posts:
            if self.mode == "strict":
                return self._generate_empty_report_strict()
            else:
                return self._generate_empty_report_lenient()
        
        # Good NewsæŠ½å‡ºï¼ˆä¸Šä½3-5ä»¶ã€ã‚¹ã‚³ã‚¢6.0ä»¥ä¸Šï¼‰
        good_news = [post for post in posts if post['score'] >= 6.0][:5]
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†é¡
        categorized = defaultdict(list)
        for post in posts:
            category = self.categorize_post(post)
            categorized[category].append(post)
        
        # ã‚«ãƒ†ã‚´ãƒªåã®æ—¥æœ¬èªåŒ–
        category_names = {
            'new_products': 'ğŸš€ æ–°è£½å“ãƒ»æ©Ÿèƒ½',
            'funding': 'ğŸ’° è³‡é‡‘èª¿é”',
            'partnership_hiring': 'ğŸ¤ ææºãƒ»æ¡ç”¨',
            'research': 'ğŸ”¬ ç ”ç©¶ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯',
            'regulation': 'âš–ï¸ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»è¦åˆ¶',
            'community': 'ğŸ’¬ ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£'
        }
        
        # æœ€æ–°ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        last_timestamp = max(post['timestamp'] for post in posts if post['timestamp'])
        
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºãƒ¬ãƒãƒ¼ãƒˆ - {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f8fafe;
            color: #2d3748;
        }}
        .container {{
            max-width: 1000px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }}
        .header h1 {{
            margin: 0;
            font-size: 2.2em;
            font-weight: 600;
        }}
        .subtitle {{
            margin: 12px 0 0 0;
            opacity: 0.9;
            font-size: 1em;
        }}
        .content {{
            padding: 30px;
        }}
        
        /* ãƒ‡ã‚¤ãƒªãƒ¼SNSã‚µãƒãƒªãƒ¼ */
        .daily-summary {{
            background: linear-gradient(135deg, #e6fffa 0%, #b2f5ea 100%);
            border-left: 5px solid #38b2ac;
            padding: 25px;
            border-radius: 8px;
            margin-bottom: 30px;
        }}
        .daily-summary h2 {{
            margin: 0 0 15px 0;
            color: #234e52;
            font-size: 1.3em;
        }}
        .summary-points {{
            list-style: none;
            padding: 0;
            margin: 0;
        }}
        .summary-points li {{
            margin-bottom: 8px;
            padding-left: 20px;
            position: relative;
            color: #2d3748;
        }}
        .summary-points li:before {{
            content: "ğŸ“Œ";
            position: absolute;
            left: 0;
        }}
        
        /* Good News */
        .good-news {{
            margin-bottom: 35px;
        }}
        .good-news h2 {{
            color: #2d3748;
            border-bottom: 3px solid #48bb78;
            padding-bottom: 8px;
            margin-bottom: 20px;
        }}
        .good-news-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
        }}
        .good-news-card {{
            background: linear-gradient(135deg, #f0fff4 0%, #c6f6d5 100%);
            border: 1px solid #9ae6b4;
            padding: 20px;
            border-radius: 10px;
            border-left: 5px solid #48bb78;
        }}
        .good-news-score {{
            background: #38a169;
            color: white;
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.8em;
            font-weight: 600;
            display: inline-block;
            margin-bottom: 10px;
        }}
        .good-news-title {{
            font-weight: 600;
            color: #22543d;
            margin-bottom: 8px;
            font-size: 1.05em;
        }}
        .good-news-summary {{
            color: #2f855a;
            font-size: 0.9em;
            margin-bottom: 12px;
        }}
        .good-news-meta {{
            font-size: 0.8em;
            color: #68d391;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }}
        .good-news-url {{
            color: #3182ce;
            text-decoration: none;
        }}
        .good-news-url:hover {{
            text-decoration: underline;
        }}
        
        /* ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´° */
        .category-section {{
            margin-bottom: 30px;
        }}
        .category-header {{
            background: #4a5568;
            color: white;
            padding: 12px 20px;
            border-radius: 6px;
            font-weight: 600;
            font-size: 1.1em;
            margin-bottom: 15px;
        }}
        .post-list {{
            background: #f7fafc;
            border-radius: 6px;
            overflow: hidden;
        }}
        .post-item {{
            padding: 15px 20px;
            border-bottom: 1px solid #e2e8f0;
            display: grid;
            grid-template-columns: 80px 100px 1fr 60px 120px;
            gap: 15px;
            align-items: center;
            font-size: 0.9em;
        }}
        .post-item:last-child {{
            border-bottom: none;
        }}
        .post-time {{
            color: #718096;
            font-size: 0.8em;
        }}
        .post-author {{
            color: #4299e1;
            font-weight: 500;
        }}
        .post-title {{
            color: #2d3748;
            font-weight: 500;
        }}
        .post-score {{
            background: #edf2f7;
            color: #4a5568;
            padding: 3px 8px;
            border-radius: 10px;
            font-size: 0.8em;
            text-align: center;
        }}
        .post-url {{
            color: #3182ce;
            text-decoration: none;
            font-size: 0.8em;
        }}
        .post-url:hover {{
            text-decoration: underline;
        }}
        
        /* æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ */
        .verification {{
            background: #f7fafc;
            border: 1px solid #e2e8f0;
            padding: 20px;
            border-radius: 8px;
            margin-top: 30px;
        }}
        .verification h3 {{
            margin: 0 0 12px 0;
            color: #2d3748;
            font-size: 1.1em;
        }}
        .verification pre {{
            background: #edf2f7;
            padding: 12px;
            border-radius: 4px;
            overflow-x: auto;
            font-size: 0.85em;
            margin: 0;
        }}
        
        .footer {{
            background: #2d3748;
            color: white;
            padding: 20px;
            text-align: center;
            font-size: 0.9em;
        }}
        
        .fallback-notice {{
            background: #fff5b8;
            border: 1px solid #fbd38d;
            color: #744210;
            padding: 15px;
            border-radius: 6px;
            margin-bottom: 20px;
            font-size: 0.9em;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“± SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºãƒ¬ãƒãƒ¼ãƒˆ</h1>
            <div class="subtitle">{datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')} - éå»48æ™‚é–“ã®X(Twitter)åˆ†æ</div>
        </div>
        
        <div class="content">"""
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é€šçŸ¥
        if "lenient" in filter_mode:
            html_content += """
            <div class="fallback-notice">
                <strong>â€»ãƒ‡ãƒ¼ã‚¿æœªæ›´æ–°ã®ãŸã‚ä»£æ›¿çª“:</strong> æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰48æ™‚é–“é¡ã£ã¦æŠ½å‡ºã—ã¾ã—ãŸã€‚
            </div>"""
        
        # ãƒ‡ã‚¤ãƒªãƒ¼SNSã‚µãƒãƒªãƒ¼
        html_content += f"""
            <div class="daily-summary">
                <h2>ğŸ“‹ ãƒ‡ã‚¤ãƒªãƒ¼SNSã‚µãƒãƒªãƒ¼</h2>
                <ul class="summary-points">
                    <li>éå»48æ™‚é–“ã§{len(posts)}ä»¶ã®æœ‰ç›ŠãªXæŠ•ç¨¿ã‚’ç™ºè¦‹ãƒ»åˆ†æ</li>
                    <li>ã‚¹ã‚³ã‚¢8.0ä»¥ä¸Šã®æ³¨ç›®æƒ…å ±{len(good_news)}ä»¶ã‚’ç‰¹ã«é‡è¦ã¨ã—ã¦æŠ½å‡º</li>
                    <li>AIè£½å“ãƒªãƒªãƒ¼ã‚¹ãƒ»è³‡é‡‘èª¿é”ãƒ»æŠ€è¡“ææºã®å‹•å‘ãŒæ´»ç™ºåŒ–</li>
                    <li>SNSãªã‚‰ã§ã¯ã®é€Ÿå ±æ€§ã«ã‚ˆã‚Šã€å…¬å¼ç™ºè¡¨å‰ã®æƒ…å ±ã‚‚ã‚­ãƒ£ãƒƒãƒ</li>
                    <li>ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–å‘ã‘æ„æ€æ±ºå®šã«æœ‰åŠ¹ãªå…·ä½“çš„æƒ…å ±ã‚’å„ªå…ˆåé›†</li>
                </ul>
            </div>"""
        
        # Good News
        if good_news:
            html_content += """
            <div class="good-news">
                <h2>ğŸ‘ Good Newsï¼ˆæ³¨ç›®ã®é‡è¦æƒ…å ±ï¼‰</h2>
                <div class="good-news-grid">"""
            
            for post in good_news:
                title = self.generate_japanese_title(post['text'])
                summary = post['text'][:60] + ('...' if len(post['text']) > 60 else '')
                time_str = post['timestamp'].strftime('%m/%d %H:%M') if post['timestamp'] else 'æ™‚åˆ»ä¸æ˜'
                
                html_content += f"""
                    <div class="good-news-card">
                        <div class="good-news-score">ã‚¹ã‚³ã‚¢: {post['score']:.1f}</div>
                        <div class="good-news-title">{title}</div>
                        <div class="good-news-summary">{summary}</div>
                        <div class="good-news-meta">
                            <span>{post['username']} | {time_str}</span>
                            <a href="{post['url']}" target="_blank" class="good-news-url">è©³ç´°</a>
                        </div>
                    </div>"""
            
            html_content += "</div></div>"
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥è©³ç´°
        html_content += "<h2>ğŸ“Š è©³ç´°åˆ†æï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰</h2>"
        
        for category, category_posts in categorized.items():
            if not category_posts:
                continue
                
            category_name = category_names.get(category, category)
            
            html_content += f"""
            <div class="category-section">
                <div class="category-header">{category_name} ({len(category_posts)}ä»¶)</div>
                <div class="post-list">"""
            
            for post in category_posts[:10]:  # å„ã‚«ãƒ†ã‚´ãƒªæœ€å¤§10ä»¶
                title = self.generate_japanese_title(post['text'])
                time_str = post['timestamp'].strftime('%H:%M') if post['timestamp'] else '--:--'
                url_display = "è©³ç´°" if post['url'] else "ãƒªãƒ³ã‚¯ãªã—"
                
                html_content += f"""
                    <div class="post-item">
                        <div class="post-time">{time_str}</div>
                        <div class="post-author">{post['username']}</div>
                        <div class="post-title">{title}</div>
                        <div class="post-score">{post['score']:.1f}</div>
                        <div><a href="{post['url']}" target="_blank" class="post-url">{url_display}</a></div>
                    </div>"""
            
            html_content += "</div></div>"
        
        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
        verification_data = {
            "total_rows": total_rows,
            "filtered_48h": filtered_48h,
            "selected_useful": len(posts),
            "good_news_count": len(good_news),
            "last_timestamp": last_timestamp.isoformat() if last_timestamp else None,
            "mode": filter_mode
        }
        
        html_content += f"""
            <div class="verification">
                <h3>ğŸ” æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿</h3>
                <pre>{json.dumps(verification_data, ensure_ascii=False, indent=2)}</pre>
            </div>
        </div>
        
        <div class="footer">
            <p>ğŸ“± Generated by SNS Insight Extraction Agent</p>
            <p>X(Twitter) ãƒ‡ãƒ¼ã‚¿åˆ†æ | æœ‰ç›Šåº¦ã‚¹ã‚³ã‚¢é‡ã¿ä»˜ã‘ | ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤é‡è¦–</p>
        </div>
    </div>
</body>
</html>"""
        
        return html_content
    
    def _generate_empty_report_strict(self) -> str:
        """å³å¯†ãƒ¢ãƒ¼ãƒ‰ï¼šç©ºçµæœãƒ¬ãƒãƒ¼ãƒˆ"""
        return """
        <div style="text-align: center; padding: 40px; color: #718096;">
            <h2>ğŸ“± SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºçµæœ</h2>
            <p><strong>48æ™‚é–“ä»¥å†…ã®è©²å½“ã¯0ä»¶</strong></p>
        </div>
        """
    
    def _generate_empty_report_lenient(self) -> str:
        """å¯›å®¹ãƒ¢ãƒ¼ãƒ‰ï¼šç©ºçµæœãƒ¬ãƒãƒ¼ãƒˆ"""
        return """
        <div style="text-align: center; padding: 40px; color: #718096;">
            <h2>ğŸ“± SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºçµæœ</h2>
            <p>æœ‰ç›ŠãªæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚</p>
            <p>â€»ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®æ›´æ–°ã‚’ãŠå¾…ã¡ãã ã•ã„</p>
        </div>
        """
    
    def run(self) -> str:
        """ãƒ¡ã‚¤ãƒ³å‡¦ç†å®Ÿè¡Œ"""
        print("ğŸš€ SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆæŠ½å‡ºã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹å§‹")
        
        # 1. CSVãƒ‡ãƒ¼ã‚¿å–å¾—
        raw_posts = self.fetch_csv_data()
        if not raw_posts:
            return self._generate_empty_report_strict()
        
        total_rows = len(raw_posts)
        
        # 2. æ­£è¦åŒ–
        normalized_posts = self.normalize_posts(raw_posts)
        if not normalized_posts:
            return self._generate_empty_report_strict()
        
        # 3. 48æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿
        filtered_posts, filter_mode = self.filter_48h(normalized_posts)
        filtered_48h = len(filtered_posts)
        
        if not filtered_posts:
            if self.mode == "strict":
                return self._generate_empty_report_strict()
            else:
                return self._generate_empty_report_lenient()
        
        # 4. æœ‰ç›ŠæŠ•ç¨¿æŠ½å‡º
        useful_posts = self.filter_useful_posts(filtered_posts)
        
        # 5. HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        html_report = self.generate_html_report(
            useful_posts, filter_mode, total_rows, filtered_48h
        )
        
        return html_report

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    mode = os.getenv('SNS_MODE', 'lenient')  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ lenient
    
    extractor = SNSInsightExtractor(mode=mode)
    html_report = extractor.run()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    today_str = datetime.now().strftime('%Y%m%d')
    report_filename = f'sns_insight_report_{today_str}.html'
    
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(html_report)
    
    with open('sns_insight_report_latest.html', 'w', encoding='utf-8') as f:
        f.write(html_report)
    
    print(f"âœ… SNSã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_filename}")

if __name__ == "__main__":
    main()