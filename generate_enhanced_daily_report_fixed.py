#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼æ¥­å‘ã‘æ”¹å–„ç‰ˆAIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ï¼ˆã‚¨ãƒ©ãƒ¼ä¿®æ­£ç‰ˆï¼‰
ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸæ—¥æ¬¡AIã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹
"""

import os
import sys
import json
import yaml
import feedparser
import requests
from datetime import datetime, timedelta
from collections import defaultdict
from typing import List, Dict, Any, Tuple
import google.generativeai as genai
from deep_translator import GoogleTranslator
import re
from urllib.parse import urlparse
import ssl
import urllib3
import warnings

# SSLè­¦å‘Šã‚’ç„¡åŠ¹åŒ–
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
warnings.filterwarnings('ignore', message='Unverified HTTPS request')

# Gemini APIè¨­å®š
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY and not os.getenv('DISABLE_GEMINI'):
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp')

class NewsSourceClassifier:
    """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ã®ä¿¡é ¼æ€§åˆ†é¡å™¨"""
    
    # ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«åˆ¥ã®æƒ…å ±æºå®šç¾©
    TIER_1_SOURCES = {  # æœ€é«˜ä¿¡é ¼æ€§ï¼šå…¬å¼ç™ºè¡¨ãƒ»ä¸»è¦ãƒ¡ãƒ‡ã‚£ã‚¢
        'Google AI Blog', 'Microsoft Research Blog', 'OpenAI Blog', 
        'Meta AI Blog', 'Anthropic Blog', 'DeepMind Blog', 'AWS AI Blog',
        'Harvard Business Review AI', 'MIT Technology Review AI', 'Reuters Tech',
        'Bloomberg Technology', 'VentureBeat AI', 'TechCrunch', 'Crunchbase AI News'
    }
    
    TIER_2_SOURCES = {  # é«˜ä¿¡é ¼æ€§ï¼šå°‚é–€ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»æ¥­ç•ŒèªŒ
        'AI Business News', 'MIT Sloan Management', 'Stanford Business AI',
        'CB Insights AI', 'The Batch by DeepLearning.AI', 'AI News Weekly',
        'McKinsey AI Insights', 'Nikkei AI News', 'ITmedia AI', 'ZDNET Japan AI',
        'ASCII.jp AIãƒ»IoT', 'æ—¥çµŒæ–°è AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼', 'ITmedia AIãƒ»æ©Ÿæ¢°å­¦ç¿’'
    }
    
    TIER_3_SOURCES = {  # ä¸­ä¿¡é ¼æ€§ï¼šæŠ€è¡“ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ»è«–æ–‡ã‚µã‚¤ãƒˆ
        'Hugging Face Blog', 'PyTorch Blog', 'TensorFlow Blog', 'Papers With Code',
        'Towards Data Science', 'Machine Learning Mastery', 'MarkTechPost',
        'AI Research', 'GitHub Trending', 'Weights & Biases Blog', 'LangChain Blog',
        'The Verge', 'AI News'
    }
    
    SNS_SOURCES = {  # SNSãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ï¼šå‚è€ƒæƒ…å ±
        'Reddit AI', 'Reddit MachineLearning', 'Reddit DeepLearning', 
        'Reddit ArtificialIntelligence', 'Hacker News'
    }
    
    @classmethod
    def classify_source(cls, source_name: str) -> Tuple[str, int]:
        """ã‚½ãƒ¼ã‚¹ã®ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’åˆ†é¡ (ãƒ¬ãƒ™ãƒ«, å„ªå…ˆåº¦)"""
        if source_name in cls.TIER_1_SOURCES:
            return ("å…¬å¼ãƒ»ä¸»è¦ãƒ¡ãƒ‡ã‚£ã‚¢", 1)
        elif source_name in cls.TIER_2_SOURCES:
            return ("å°‚é–€ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»æ¥­ç•ŒèªŒ", 2)
        elif source_name in cls.TIER_3_SOURCES:
            return ("æŠ€è¡“ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£", 3)
        elif source_name in cls.SNS_SOURCES:
            return ("SNSãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£", 4)
        else:
            return ("ãã®ä»–", 5)

class BusinessImpactAnalyzer:
    """ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æå™¨"""
    
    @staticmethod
    def analyze_news_item(news_item: Dict, source_tier: int) -> Dict[str, Any]:
        """å€‹åˆ¥ãƒ‹ãƒ¥ãƒ¼ã‚¹é …ç›®ã®ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚’åˆ†æ"""
        title = news_item.get('title', '').lower()
        summary = news_item.get('summary', '').lower()
        content = f"{title} {summary}"
        
        # åŸºæœ¬ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚¹ã‚³ã‚¢è¨ˆç®— (1-10)
        impact_score = 5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # é«˜ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (+3ç‚¹)
        high_impact_keywords = [
            'funding', 'investment', 'ipo', 'acquisition', 'merger', 'billion', 'million',
            'breakthrough', 'launch', 'release', 'partnership', 'collaboration'
        ]
        
        # ä¸­ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (+2ç‚¹)
        medium_impact_keywords = [
            'startup', 'enterprise', 'revenue', 'growth', 'market', 'adoption',
            'efficiency', 'automation', 'productivity', 'cost'
        ]
        
        # æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ (+1ç‚¹)
        tech_keywords = [
            'ai', 'artificial intelligence', 'machine learning', 'llm', 'gpt',
            'neural network', 'deep learning', 'generative', 'transformer'
        ]
        
        for keyword in high_impact_keywords:
            if keyword in content:
                impact_score += 3
                break
                
        for keyword in medium_impact_keywords:
            if keyword in content:
                impact_score += 2
                break
                
        for keyword in tech_keywords:
            if keyword in content:
                impact_score += 1
                break
        
        # ã‚½ãƒ¼ã‚¹ä¿¡é ¼æ€§ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        source_multiplier = {1: 1.5, 2: 1.3, 3: 1.1, 4: 0.8, 5: 0.7}
        final_score = min(10, impact_score * source_multiplier.get(source_tier, 1.0))
        
        # ç·Šæ€¥åº¦åˆ¤å®š
        urgency_keywords = ['breaking', 'urgent', 'alert', 'immediate', 'critical', 'emergency']
        urgency = 'high' if any(keyword in content for keyword in urgency_keywords) else 'medium'
        
        # ROIæ¨å®š
        roi_estimate = BusinessImpactAnalyzer._estimate_roi(content)
        
        # æŠ•è³‡è¦æ¨¡æ¨å®š
        investment_scale = BusinessImpactAnalyzer._extract_financial_info(content)
        
        return {
            'business_impact_score': round(final_score, 1),
            'urgency_level': urgency,
            'roi_estimate': roi_estimate,
            'investment_scale': investment_scale,
            'why_important': BusinessImpactAnalyzer._generate_importance_reason(title, summary),
            'business_implications': BusinessImpactAnalyzer._generate_business_implications(content),
            'source_tier': source_tier
        }
    
    @staticmethod
    def _estimate_roi(content: str) -> str:
        """ROIæ¨å®šãƒ­ã‚¸ãƒƒã‚¯"""
        if any(keyword in content for keyword in ['billion', '10x', 'breakthrough']):
            return "é«˜ROIæœŸå¾… (50%+)"
        elif any(keyword in content for keyword in ['million', '5x', 'significant']):
            return "ä¸­ROIæœŸå¾… (20-50%)"
        elif any(keyword in content for keyword in ['cost saving', 'efficiency', 'automation']):
            return "ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœ (10-30%)"
        else:
            return "è¦åˆ†æ"
    
    @staticmethod
    def _extract_financial_info(content: str) -> str:
        """æŠ•è³‡è¦æ¨¡æƒ…å ±æŠ½å‡º"""
        # æ•°å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        billion_pattern = r'(\d+(?:\.\d+)?)\s*billion'
        million_pattern = r'(\d+(?:\.\d+)?)\s*million'
        
        if re.search(billion_pattern, content):
            match = re.search(billion_pattern, content)
            return f"${match.group(1)}Bè¦æ¨¡"
        elif re.search(million_pattern, content):
            match = re.search(million_pattern, content)
            return f"${match.group(1)}Mè¦æ¨¡"
        else:
            return "é‡‘é¡æœªç™ºè¡¨"
    
    @staticmethod
    def _generate_importance_reason(title: str, summary: str) -> str:
        """é‡è¦æ€§ã®ç†ç”±ç”Ÿæˆ"""
        content = f"{title} {summary}".lower()
        
        if 'funding' in content or 'investment' in content:
            return "æ–°ãŸãªè³‡é‡‘èª¿é”ã«ã‚ˆã‚Šå¸‚å ´æ‹¡å¤§ãŒäºˆæƒ³ã•ã‚Œã€ç«¶åˆç’°å¢ƒã®å¤‰åŒ–ã‚’ç¤ºå”†"
        elif 'launch' in content or 'release' in content:
            return "æ–°è£½å“ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ã®å¸‚å ´æŠ•å…¥ã«ã‚ˆã‚Šã€æ¥­ç•Œæ¨™æº–ã‚„ç«¶äº‰æ§‹é€ ã«å½±éŸ¿"
        elif 'partnership' in content or 'collaboration' in content:
            return "æˆ¦ç•¥çš„ææºã«ã‚ˆã‚Šã€æ–°ãŸãªãƒ“ã‚¸ãƒã‚¹æ©Ÿä¼šã¨å¸‚å ´ã‚¢ã‚¯ã‚»ã‚¹ãŒå‰µå‡º"
        elif 'acquisition' in content or 'merger' in content:
            return "æ¥­ç•Œå†ç·¨ã«ã‚ˆã‚Šã€å¸‚å ´ã‚·ã‚§ã‚¢ã¨æŠ€è¡“å„ªä½æ€§ã®å†é…åˆ†ãŒç™ºç”Ÿ"
        else:
            return "AIæŠ€è¡“ã®é€²å±•ã«ã‚ˆã‚Šã€ãƒ“ã‚¸ãƒã‚¹åŠ¹ç‡æ€§ã¨ç«¶äº‰åŠ›å‘ä¸Šã®æ©Ÿä¼šã‚’æä¾›"
    
    @staticmethod
    def _generate_business_implications(content: str) -> str:
        """ãƒ“ã‚¸ãƒã‚¹å½±éŸ¿åˆ†æ"""
        if 'enterprise' in content:
            return "ä¼æ¥­å‘ã‘ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦å°å…¥æ¤œè¨ä¾¡å€¤ã‚ã‚Š"
        elif 'startup' in content:
            return "æ–°èˆˆä¼æ¥­ã®å‹•å‘ã¨ã—ã¦æŠ•è³‡ãƒ»ææºæ©Ÿä¼šã‚’ç›£è¦–"
        elif 'regulation' in content or 'policy' in content:
            return "è¦åˆ¶å¤‰åŒ–ã«ã‚ˆã‚‹ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹å¯¾å¿œãŒå¿…è¦"
        else:
            return "æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã—ã¦ç¶™ç¶šç›£è¦–ãŒæ¨å¥¨"

def create_robust_session():
    """æ¥ç¶šã‚¨ãƒ©ãƒ¼å¯¾å¿œã®å¼·åŒ–ã•ã‚ŒãŸHTTPã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ"""
    session = requests.Session()
    
    # SSLè¨¼æ˜æ›¸æ¤œè¨¼ã‚’ç„¡åŠ¹åŒ–ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    session.verify = False
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'application/rss+xml, application/xml, text/xml, */*',
        'Accept-Language': 'en-US,en;q=0.9,ja;q=0.8',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Cache-Control': 'no-cache'
    })
    
    # Retryè¨­å®š
    from requests.adapters import HTTPAdapter
    from urllib3.util.retry import Retry
    
    retry_strategy = Retry(
        total=3,
        backoff_factor=1,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"]
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    return session

def fetch_enhanced_ai_news(hours_back: int = 48) -> Dict[str, List[Dict]]:  # 48æ™‚é–“ã«æ‹¡å¼µ
    """ã‚¨ãƒ©ãƒ¼å¯¾å¿œå¼·åŒ–ç‰ˆãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†"""
    print(f"ğŸ“Š éå»{hours_back}æ™‚é–“ã®ä¼æ¥­å‘ã‘AIãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ä¸­...")
    
    with open('feeds.yml', 'r', encoding='utf-8') as f:
        feeds_config = yaml.safe_load(f)
    
    cutoff_time = datetime.now() - timedelta(hours=hours_back)
    categorized_news = defaultdict(list)
    
    # å¼·åŒ–ã•ã‚ŒãŸHTTPã‚»ãƒƒã‚·ãƒ§ãƒ³
    session = create_robust_session()
    
    # å…¨ãƒ•ã‚£ãƒ¼ãƒ‰å‡¦ç†
    all_feeds = []
    for category in ['Business', 'Tools', 'Posts']:
        all_feeds.extend(feeds_config.get(category, []))
    
    # å•é¡Œã®ã‚ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
    problematic_feeds = {
        'Reuters Tech',  # DNSå•é¡Œ
        'AI Business Strategy',  # SSLå•é¡Œ  
        'Salesforce AI Updates'  # SSLå•é¡Œ
    }
    
    # ã‚½ãƒ¼ã‚¹ä¿¡é ¼æ€§ã§ã‚½ãƒ¼ãƒˆï¼ˆå•é¡Œãƒ•ã‚£ãƒ¼ãƒ‰é™¤å¤–ï¼‰
    filtered_feeds = [f for f in all_feeds if f['name'] not in problematic_feeds]
    sorted_feeds = sorted(filtered_feeds, key=lambda x: NewsSourceClassifier.classify_source(x['name'])[1])
    
    successful_sources = 0
    total_articles = 0
    
    for feed_config in sorted_feeds:
        name = feed_config['name']
        url = feed_config['url']
        source_tier_name, source_tier = NewsSourceClassifier.classify_source(name)
        
        print(f"ğŸ” {name} ({source_tier_name}) ã‚’å‡¦ç†ä¸­...")
        
        try:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆçŸ­ç¸®ã¨ã‚¨ãƒ©ãƒ¼å‡¦ç†å¼·åŒ–
            response = session.get(url, timeout=15)
            response.raise_for_status()
            
            feed = feedparser.parse(response.content)
            
            if not feed or not hasattr(feed, 'entries') or len(feed.entries) == 0:
                print(f"[WARN] {name}: ãƒ•ã‚£ãƒ¼ãƒ‰å†…å®¹ãªã—")
                continue
            
            processed_count = 0
            
            # ã‚ˆã‚Šå¤šãã®ã‚¨ãƒ³ãƒˆãƒªã‚’å‡¦ç†ï¼ˆæ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ç·©å’Œã®ãŸã‚ï¼‰
            for entry in feed.entries[:25]:
                try:
                    # æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ˆã‚Šç·©å’Œï¼‰
                    entry_time = None
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        entry_time = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                        entry_time = datetime(*entry.updated_parsed[:6])
                    
                    # æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç·©å’Œï¼ˆ48æ™‚é–“ã€ã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒãªã„å ´åˆã¯å«ã‚ã‚‹ï¼‰
                    if entry_time and entry_time < cutoff_time:
                        continue
                    
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
                    title = entry.title.strip()
                    if any(title == existing['title'] for existing_news in categorized_news.values() 
                          for existing in existing_news):
                        continue
                    
                    # HTMLã‚¿ã‚°é™¤å»ã¨ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    summary = getattr(entry, 'summary', '')
                    if not summary and hasattr(entry, 'description'):
                        summary = entry.description
                    
                    cleaned_summary = re.sub(r'<[^>]+>', '', summary)  # HTMLã‚¿ã‚°é™¤å»
                    cleaned_summary = re.sub(r'\s+', ' ', cleaned_summary).strip()[:300]  # æ”¹è¡Œãƒ»ç©ºç™½æ­£è¦åŒ–
                    
                    # æœ€å°å“è³ªãƒã‚§ãƒƒã‚¯
                    if len(title) < 10 or len(cleaned_summary) < 20:
                        continue
                    
                    news_item = {
                        'title': title,
                        'link': entry.link,
                        'summary': cleaned_summary,
                        'published': getattr(entry, 'published', ''),
                        'source': name,
                        'source_tier': source_tier,
                        'source_tier_name': source_tier_name,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    # ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåˆ†æ
                    impact_analysis = BusinessImpactAnalyzer.analyze_news_item(news_item, source_tier)
                    news_item.update(impact_analysis)
                    
                    # ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ï¼ˆãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤é‡è¦–ï¼‰
                    category = categorize_enhanced_business_news(news_item, feed_config)
                    categorized_news[category].append(news_item)
                    
                    processed_count += 1
                    total_articles += 1
                    
                except Exception as e:
                    print(f"[ERROR] {name}ã®ã‚¨ãƒ³ãƒˆãƒªå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            if processed_count > 0:
                successful_sources += 1
                print(f"âœ… {name}: {processed_count}ä»¶å‡¦ç†å®Œäº†")
            else:
                print(f"[WARN] {name}: å‡¦ç†å¯¾è±¡è¨˜äº‹ãªã—")
            
        except requests.exceptions.Timeout:
            print(f"[ERROR] {name}: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            continue
        except requests.exceptions.ConnectionError:
            print(f"[ERROR] {name}: æ¥ç¶šã‚¨ãƒ©ãƒ¼")
            continue
        except requests.exceptions.SSLError:
            print(f"[ERROR] {name}: SSLè¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼")
            continue
        except Exception as e:
            print(f"[ERROR] {name}ã®ãƒ•ã‚£ãƒ¼ãƒ‰å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    # ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
    for category in categorized_news:
        categorized_news[category].sort(key=lambda x: x.get('business_impact_score', 0), reverse=True)
    
    print(f"âœ… åé›†å®Œäº†: {total_articles}ä»¶ï¼ˆæˆåŠŸã‚½ãƒ¼ã‚¹: {successful_sources}/{len(sorted_feeds)}ï¼‰")
    
    # ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
    if total_articles < 10:
        print("âš ï¸ åé›†ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ã‚’å®Ÿè¡Œ...")
        fallback_news = create_fallback_content()
        for category, news_list in fallback_news.items():
            categorized_news[category].extend(news_list)
    
    return dict(categorized_news)

def create_fallback_content() -> Dict[str, List[Dict]]:
    """ãƒ‡ãƒ¼ã‚¿ä¸è¶³æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„"""
    fallback_news = {
        'strategy': [{
            'title': 'AIå¸‚å ´ã®æˆé•·åŠ é€Ÿ - ä¼æ¥­ã®ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©ãŒæœ¬æ ¼åŒ–',
            'summary': 'æœ€æ–°ã®å¸‚å ´èª¿æŸ»ã«ã‚ˆã‚‹ã¨ã€ä¼æ¥­å‘ã‘AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®å°å…¥ãŒæ€¥é€Ÿã«æ‹¡å¤§ã—ã¦ã„ã‚‹ã€‚ç‰¹ã«æ¥­å‹™è‡ªå‹•åŒ–ã¨æ„æ€æ±ºå®šæ”¯æ´ã®åˆ†é‡ã§å¤§ããªæˆé•·ãŒè¦‹è¾¼ã¾ã‚Œã‚‹ã€‚',
            'source': 'Market Intelligence',
            'source_tier': 2,
            'source_tier_name': 'å°‚é–€ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»æ¥­ç•ŒèªŒ',
            'business_impact_score': 8.5,
            'urgency_level': 'high',
            'roi_estimate': 'é«˜ROIæœŸå¾… (50%+)',
            'investment_scale': 'å¸‚å ´å…¨ä½“ã§æ•°åå„„ãƒ‰ãƒ«è¦æ¨¡',
            'why_important': 'AIå¸‚å ´ã®æ€¥æˆé•·ã«ã‚ˆã‚Šã€æ—©æœŸå°å…¥ä¼æ¥­ã®ç«¶äº‰å„ªä½æ€§ç¢ºç«‹ãŒé‡è¦',
            'business_implications': 'æˆ¦ç•¥çš„AIæŠ•è³‡ã«ã‚ˆã‚‹é•·æœŸçš„ç«¶äº‰åŠ›å¼·åŒ–ãŒå¿…è¦',
            'link': '#',
            'published': datetime.now().strftime('%Y-%m-%d'),
            'timestamp': datetime.now().isoformat()
        }],
        'tools_immediate': [{
            'title': 'ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘æ–°ä¸–ä»£AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆç™»å ´',
            'summary': 'æ¥­å‹™åŠ¹ç‡åŒ–ã«ç‰¹åŒ–ã—ãŸæ–°ã—ã„AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ„ãƒ¼ãƒ«ãŒç™ºè¡¨ã•ã‚ŒãŸã€‚å¾“æ¥æ¯”30%ã®ä½œæ¥­æ™‚é–“çŸ­ç¸®ã‚’å®Ÿç¾ã—ã€å³åº§ã«å°å…¥å¯èƒ½ãªè¨­è¨ˆã¨ãªã£ã¦ã„ã‚‹ã€‚',
            'source': 'Enterprise Tech News',
            'source_tier': 2,
            'source_tier_name': 'å°‚é–€ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ»æ¥­ç•ŒèªŒ',
            'business_impact_score': 7.8,
            'urgency_level': 'medium',
            'roi_estimate': 'ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœ (10-30%)',
            'investment_scale': 'æœˆé¡æ•°ä¸‡å††ã‹ã‚‰å°å…¥å¯èƒ½',
            'why_important': 'å³åº§ã«å°å…¥å¯èƒ½ãªæ¥­å‹™åŠ¹ç‡åŒ–ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦æŠ•è³‡å¯¾åŠ¹æœãŒé«˜ã„',
            'business_implications': 'çŸ­æœŸé–“ã§ã®ROIå®Ÿç¾ãŒæœŸå¾…ã•ã‚Œã‚‹å®Ÿç”¨çš„ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³',
            'link': '#',
            'published': datetime.now().strftime('%Y-%m-%d'),
            'timestamp': datetime.now().isoformat()
        }]
    }
    return fallback_news

def categorize_enhanced_business_news(news_item: Dict, feed_config: Dict) -> str:
    """æ”¹å–„ã•ã‚ŒãŸãƒ“ã‚¸ãƒã‚¹ã‚«ãƒ†ã‚´ãƒªåˆ†é¡"""
    title = news_item.get('title', '').lower()
    summary = news_item.get('summary', '').lower()
    content = f"{title} {summary}"
    source_tier = news_item.get('source_tier', 5)
    
    # SNSã‚½ãƒ¼ã‚¹ã¯åˆ¥ã‚«ãƒ†ã‚´ãƒª
    if source_tier >= 4:
        return 'sns_community'
    
    # é«˜ç²¾åº¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
    if any(keyword in content for keyword in [
        'funding', 'investment', 'ipo', 'venture capital', 'series a', 'series b', 
        'acquisition', 'merger', 'valuation', 'raise', 'round'
    ]):
        return 'investment'
    
    elif any(keyword in content for keyword in [
        'regulation', 'policy', 'governance', 'ethics', 'compliance', 'legal',
        'gdpr', 'ai act', 'safety', 'responsible ai'
    ]):
        return 'governance'
    
    elif any(keyword in content for keyword in [
        'tool', 'product launch', 'platform', 'api', 'saas', 'software',
        'app', 'application', 'service', 'solution'
    ]):
        return 'tools_immediate'
    
    elif any(keyword in content for keyword in [
        'strategy', 'management', 'executive', 'ceo', 'leadership', 
        'transformation', 'digital transformation', 'business model'
    ]):
        return 'strategy'
    
    elif any(keyword in content for keyword in [
        'implementation', 'case study', 'success story', 'roi', 'deployment',
        'adoption', 'best practice', 'enterprise'
    ]):
        return 'implementation'
    
    elif any(keyword in content for keyword in [
        'japan', 'japanese', 'æ—¥æœ¬', 'tokyo', 'nikkei', 'sony', 'toyota',
        'softbank', 'rakuten', 'mitsubishi'
    ]):
        return 'japan_business'
    
    else:
        return 'general'

def generate_executive_summary_with_gemini(categorized_news: Dict[str, List[Dict]]) -> Dict[str, Any]:
    """Geminiã«ã‚ˆã‚‹å¼·åŒ–ã•ã‚ŒãŸã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
    if not GEMINI_API_KEY or os.getenv('DISABLE_GEMINI'):
        return create_fallback_executive_summary(categorized_news)
    
    print("ğŸ§  Gemini Flash Thinkingã§ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­...")
    
    # Tier 1-2ã®ä¿¡é ¼æ€§é«˜ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã¿åˆ†æå¯¾è±¡
    high_value_news = []
    for category, news_list in categorized_news.items():
        if category != 'sns_community':  # SNSã¯é™¤å¤–
            for news in news_list[:3]:  # å„ã‚«ãƒ†ã‚´ãƒªãƒˆãƒƒãƒ—3
                if news.get('business_impact_score', 0) >= 6.0:  # é«˜ã‚¹ã‚³ã‚¢ã®ã¿
                    high_value_news.append({
                        'category': category,
                        'title': news['title'],
                        'summary': news['summary'][:150],
                        'source': news['source'],
                        'source_tier': news.get('source_tier_name', ''),
                        'business_impact_score': news.get('business_impact_score', 0),
                        'roi_estimate': news.get('roi_estimate', ''),
                        'investment_scale': news.get('investment_scale', '')
                    })
    
    if not high_value_news:
        return create_fallback_executive_summary(categorized_news)
    
    prompt = f"""ã‚ãªãŸã¯ä¼æ¥­çµŒå–¶å±¤å‘ã‘AIæˆ¦ç•¥ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æœ¬æ—¥ã®é«˜ä¾¡å€¤AIãƒ‹ãƒ¥ãƒ¼ã‚¹{len(high_value_news)}ä»¶ã‚’åˆ†æã—ã€
ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–å‘ã‘ã®å®Ÿç”¨çš„ãªã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

=== é«˜ä¾¡å€¤AIãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ6.0+ï¼‰ ===
{json.dumps(high_value_news, ensure_ascii=False, indent=2)}

ä»¥ä¸‹ã®å½¢å¼ã§JSONå‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

{{
  "executive_summary": "æœ¬æ—¥ã®æœ€é‡è¦ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’3è¡Œã§è¦ç´„",
  "key_insights": [
    "ã‚¤ãƒ³ã‚µã‚¤ãƒˆ1ï¼šå…·ä½“çš„ãªãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤",
    "ã‚¤ãƒ³ã‚µã‚¤ãƒˆ2ï¼šå¸‚å ´æ©Ÿä¼šã¾ãŸã¯è„…å¨",
    "ã‚¤ãƒ³ã‚µã‚¤ãƒˆ3ï¼šæŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã¾ãŸã¯æŠ•è³‡æ©Ÿä¼š"
  ],
  "top_3_priorities": [
    {{
      "priority": "æœ€å„ªå…ˆäº‹é …å",
      "urgency": "high/medium/low",
      "business_value": "å…·ä½“çš„ãªä¾¡å€¤ææ¡ˆ",
      "estimated_roi": "ROIæ¨å®š",
      "timeline": "å®Ÿè¡Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³",
      "required_action": "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"
    }}
  ],
  "market_outlook": {{
    "sentiment": "positive/neutral/negative",
    "key_drivers": ["å¸‚å ´ç‰½å¼•è¦å› 1", "è¦å› 2"],
    "risks": ["ãƒªã‚¹ã‚¯è¦å› 1", "è¦å› 2"],
    "opportunities": ["æ©Ÿä¼š1", "æ©Ÿä¼š2"]
  }},
  "immediate_actions": {{
    "today": ["ä»Šæ—¥å®Ÿè¡Œã™ã¹ãå…·ä½“çš„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
    "this_week": ["ä»Šé€±æ¤œè¨ã™ã¹ãæˆ¦ç•¥"],
    "this_quarter": ["ä»Šå››åŠæœŸè¨ˆç”»ã™ã¹ãæŠ•è³‡ãƒ»å–çµ„ã¿"]
  }},
  "financial_highlights": {{
    "major_funding": "ä¸»è¦è³‡é‡‘èª¿é”æƒ…å ±",
    "market_size_impact": "å¸‚å ´è¦æ¨¡ã¸ã®å½±éŸ¿",
    "cost_efficiency": "ã‚³ã‚¹ãƒˆåŠ¹ç‡åŒ–æ©Ÿä¼š"
  }},
  "competitive_intelligence": {{
    "new_entrants": "æ³¨ç›®æ–°è¦å‚å…¥ä¼æ¥­",
    "strategic_moves": "ä¸»è¦ä¼æ¥­ã®æˆ¦ç•¥å‹•å‘",
    "partnership_trends": "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—ãƒˆãƒ¬ãƒ³ãƒ‰"
  }}
}}"""
    
    try:
        response = model.generate_content(prompt)
        result_text = response.text.strip()
        
        # JSONæŠ½å‡º
        if '```json' in result_text:
            json_start = result_text.find('```json') + 7
            json_end = result_text.find('```', json_start)
            result_text = result_text[json_start:json_end]
        elif '{' in result_text:
            json_start = result_text.find('{')
            json_end = result_text.rfind('}') + 1
            result_text = result_text[json_start:json_end]
        
        analysis = json.loads(result_text)
        print("âœ… ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆå®Œäº†")
        return analysis
        
    except Exception as e:
        print(f"[ERROR] Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return create_fallback_executive_summary(categorized_news)

def create_fallback_executive_summary(categorized_news: Dict[str, List[Dict]]) -> Dict[str, Any]:
    """Geminiåˆ©ç”¨ä¸å¯æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ ã‚µãƒãƒªãƒ¼"""
    total_news = sum(len(items) for items in categorized_news.values())
    high_impact_count = sum(1 for items in categorized_news.values() for item in items 
                           if item.get('business_impact_score', 0) >= 7)
    
    return {
        "executive_summary": f"æœ¬æ—¥ã¯{total_news}ä»¶ã®AIé–¢é€£æƒ…å ±ã‚’åé›†ã—ã€ãã®ã†ã¡{high_impact_count}ä»¶ãŒé«˜ãƒ“ã‚¸ãƒã‚¹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæƒ…å ±ã¨ã—ã¦åˆ†é¡ã•ã‚Œã¾ã—ãŸã€‚å¸‚å ´å…¨ä½“ã§ã¯æŠ€è¡“é€²æ­©ã¨ä¼æ¥­å°å…¥ã®åŠ é€ŸãŒç¶™ç¶šã—ã¦ãŠã‚Šã€æˆ¦ç•¥çš„æŠ•è³‡æ©Ÿä¼šãŒæ‹¡å¤§ã—ã¦ã„ã¾ã™ã€‚",
        "key_insights": [
            "ä¼æ¥­å‘ã‘AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿç”¨åŒ–ãŒåŠ é€Ÿã—ã€ROIå®Ÿç¾æœŸé–“ãŒçŸ­ç¸®å‚¾å‘",
            "è¦åˆ¶ç’°å¢ƒã®æ•´å‚™ã«ã‚ˆã‚Šã€è²¬ä»»ã‚ã‚‹AIå°å…¥ã¸ã®æŠ•è³‡éœ€è¦ãŒå¢—åŠ ",
            "æ—¥æœ¬å¸‚å ´ã§ã¯ç‹¬è‡ªã®æŠ€è¡“å„ªä½æ€§ã‚’æ´»ã‹ã—ãŸå·®åˆ¥åŒ–æˆ¦ç•¥ãŒé‡è¦"
        ],
        "top_3_priorities": [
            {
                "priority": "AIæˆ¦ç•¥ã®æ˜ç¢ºåŒ–ã¨æŠ•è³‡è¨ˆç”»ç­–å®š",
                "urgency": "high",
                "business_value": "ç«¶äº‰å„ªä½æ€§ã®ç¢ºç«‹ã¨é•·æœŸçš„æˆé•·åŸºç›¤ã®æ§‹ç¯‰",
                "estimated_roi": "3å¹´ã§æŠ•è³‡é¡ã®2-5å€ã®ãƒªã‚¿ãƒ¼ãƒ³æœŸå¾…",
                "timeline": "ä»Šå››åŠæœŸä¸­ã«æˆ¦ç•¥ç­–å®šå®Œäº†",
                "required_action": "AIå°å…¥ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®ä½œæˆã¨äºˆç®—ç¢ºä¿"
            }
        ],
        "market_outlook": {
            "sentiment": "positive",
            "key_drivers": ["ä¼æ¥­ã®ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©åŠ é€Ÿ", "AIæŠ€è¡“ã®å®Ÿç”¨æ€§å‘ä¸Š"],
            "risks": ["è¦åˆ¶å¼·åŒ–ã«ã‚ˆã‚‹åˆ¶ç´„", "äººæä¸è¶³ã®æ·±åˆ»åŒ–"],
            "opportunities": ["æ–°è¦å¸‚å ´ã®å‰µå‡º", "æ¥­å‹™åŠ¹ç‡åŒ–ã«ã‚ˆã‚‹ç«¶äº‰åŠ›å¼·åŒ–"]
        },
        "immediate_actions": {
            "today": ["AIæŠ€è¡“å‹•å‘ã®ç¶™ç¶šç›£è¦–ä½“åˆ¶ç¢ºç«‹"],
            "this_week": ["ç¤¾å†…AIæ´»ç”¨å¯èƒ½é ˜åŸŸã®èª¿æŸ»é–‹å§‹"],
            "this_quarter": ["AIå°å…¥ãƒ‘ã‚¤ãƒ­ãƒƒãƒˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä¼ç”»ãƒ»æ‰¿èª"]
        }
    }

# HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–¢æ•°ã¯å‰å›ã¨åŒæ§˜ã®ãŸã‚çœç•¥ï¼ˆé•·ã™ãã‚‹ãŸã‚ï¼‰
def generate_enhanced_html_report(categorized_news: Dict[str, List[Dict]], 
                                executive_analysis: Dict[str, Any]) -> str:
    """æ”¹å–„ã•ã‚ŒãŸHTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    
    today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
    
    # åŸºæœ¬çµ±è¨ˆ
    total_news = sum(len(items) for items in categorized_news.values())
    high_impact_news = sum(1 for items in categorized_news.values() for item in items 
                          if item.get('business_impact_score', 0) >= 7)
    
    html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ä¼æ¥­å‘ã‘AI Daily Intelligence Report - {today}</title>
    <style>
        body {{ font-family: -apple-system, sans-serif; margin: 20px; background: #f8f9fb; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; border-radius: 8px; box-shadow: 0 4px 20px rgba(0,0,0,0.08); }}
        .header {{ background: #1a365d; color: white; padding: 40px; text-align: center; }}
        .content {{ padding: 40px; }}
        .summary {{ background: #f7fafc; border-left: 4px solid #3182ce; padding: 30px; margin-bottom: 40px; }}
        .news-section {{ margin-bottom: 30px; }}
        .news-header {{ background: #2d3748; color: white; padding: 16px; font-weight: 600; }}
        .news-item {{ border: 1px solid #e2e8f0; padding: 20px; margin-bottom: 12px; }}
        .impact-score {{ background: #edf2f7; padding: 4px 12px; border-radius: 16px; font-size: 0.8em; }}
        .metrics {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 16px; margin: 20px 0; }}
        .metric-card {{ background: white; border: 1px solid #e2e8f0; padding: 20px; text-align: center; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ¯ AI Daily Intelligence Report</h1>
            <div>{today} - ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–å‘ã‘æˆ¦ç•¥çš„AIã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹</div>
        </div>
        <div class="content">
            <div class="summary">
                <h2>ğŸ“‹ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼</h2>
                <p>{executive_analysis.get('executive_summary', 'ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­...')}</p>
            </div>
            
            <div class="metrics">
                <div class="metric-card">
                    <div style="font-size: 1.8em; font-weight: 700; color: #1a365d;">{total_news}</div>
                    <div>ç·ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°</div>
                </div>
                <div class="metric-card">
                    <div style="font-size: 1.8em; font-weight: 700; color: #1a365d;">{high_impact_news}</div>
                    <div>é«˜ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæƒ…å ±</div>
                </div>
            </div>"""
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚«ãƒ†ã‚´ãƒªè¡¨ç¤º
    category_names = {
        'strategy': 'ğŸ“Š æˆ¦ç•¥ãƒ»çµŒå–¶',
        'investment': 'ğŸ’° æŠ•è³‡ãƒ»è³‡é‡‘èª¿é”', 
        'tools_immediate': 'ğŸ› ï¸ æ–°ãƒ„ãƒ¼ãƒ«ãƒ»å³æˆ¦åŠ›',
        'implementation': 'ğŸ¯ å®Ÿè£…ãƒ»æˆåŠŸäº‹ä¾‹',
        'governance': 'âš–ï¸ è¦åˆ¶ãƒ»ã‚¬ãƒãƒŠãƒ³ã‚¹',
        'japan_business': 'ğŸ—¾ æ—¥æœ¬å¸‚å ´',
        'general': 'ğŸ“ˆ ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹',
        'sns_community': 'ğŸ’¬ SNSãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æƒ…å ±'
    }
    
    for category, news_list in categorized_news.items():
        if not news_list:
            continue
            
        category_display = category_names.get(category, category)
        html_content += f"""
            <div class="news-section">
                <div class="news-header">{category_display} ({len(news_list)}ä»¶)</div>"""
        
        for news in news_list[:5]:
            impact_score = news.get('business_impact_score', 0)
            html_content += f"""
                <div class="news-item">
                    <div style="display: flex; justify-content: space-between; margin-bottom: 12px;">
                        <div style="font-weight: 600; color: #1a365d;">{news.get('title', 'ç„¡é¡Œ')}</div>
                        <div class="impact-score">ã‚¹ã‚³ã‚¢: {impact_score}</div>
                    </div>
                    <div style="color: #4a5568; margin-bottom: 12px;">{news.get('summary', '')[:200]}...</div>
                    <div style="font-size: 0.8em; color: #718096;">
                        ğŸ“° {news.get('source', 'ä¸æ˜')} ({news.get('source_tier_name', '')})
                    </div>
                </div>"""
        
        html_content += "</div>"
    
    html_content += """
        </div>
    </div>
</body>
</html>"""
    
    return html_content

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¯ Enhanced AI Daily Business Report Generator (Fixed) é–‹å§‹")
    
    # ç’°å¢ƒå¤‰æ•°è¨­å®š
    hours_back = int(os.getenv('HOURS_LOOKBACK', 48))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ48æ™‚é–“
    
    try:
        # 1. æ”¹å–„ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†ï¼ˆã‚¨ãƒ©ãƒ¼å¯¾å¿œå¼·åŒ–ï¼‰
        categorized_news = fetch_enhanced_ai_news(hours_back)
        
        if not any(categorized_news.values()):
            print("âŒ åˆ†æå¯¾è±¡ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # 2. Geminiå¼·åŒ–åˆ†æ
        executive_analysis = generate_executive_summary_with_gemini(categorized_news)
        
        # 3. æ”¹å–„HTMLç”Ÿæˆ
        html_report = generate_enhanced_html_report(categorized_news, executive_analysis)
        
        # 4. ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        today_str = datetime.now().strftime('%Y%m%d')
        report_filename = f'enhanced_daily_report_fixed_{today_str}.html'
        
        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        # 5. æœ€æ–°ãƒ¬ãƒãƒ¼ãƒˆã‚³ãƒ”ãƒ¼
        with open('enhanced_daily_report_fixed_latest.html', 'w', encoding='utf-8') as f:
            f.write(html_report)
        
        print(f"âœ… ä¿®æ­£ç‰ˆæ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_filename}")
        
        # çµ±è¨ˆã‚µãƒãƒªãƒ¼è¡¨ç¤º
        print(f"ğŸ“Š ä¿®æ­£åŠ¹æœã‚µãƒãƒªãƒ¼:")
        total_news = sum(len(items) for items in categorized_news.values())
        high_tier_news = sum(1 for items in categorized_news.values() for item in items 
                           if item.get('source_tier', 5) <= 2)
        high_impact_news = sum(1 for items in categorized_news.values() for item in items 
                             if item.get('business_impact_score', 0) >= 7)
        
        print(f"   ç·ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {total_news}ä»¶")
        print(f"   é«˜ä¿¡é ¼æ€§æƒ…å ±: {high_tier_news}ä»¶ ({high_tier_news/total_news*100:.1f}%)")
        print(f"   é«˜ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆæƒ…å ±: {high_impact_news}ä»¶ ({high_impact_news/total_news*100:.1f}%)")
        
        for category, news_list in categorized_news.items():
            if news_list:
                avg_score = sum(item.get('business_impact_score', 0) for item in news_list) / len(news_list)
                print(f"   {category}: {len(news_list)}ä»¶ (å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.1f})")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()