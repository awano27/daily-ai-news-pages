# -*- coding: utf-8 -*-
"""
AIãƒ‹ãƒ¥ãƒ¼ã‚¹ HTML ç”Ÿæˆï¼ˆUIå¼·åŒ–ï¼‹ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹AIæŠ½å‡ºï¼‹è¦ç´„ã®æ—¥æœ¬èªåŒ–å¯¾å¿œï¼‰
- ã‚½ãƒ¼ã‚¹ãƒªãƒ³ã‚¯ã¯åŸæ–‡ã®ã¾ã¾ã€ãƒšãƒ¼ã‚¸ã«è¡¨ç¤ºã™ã‚‹è¦ç´„ã¯æ—¥æœ¬èªåŒ–ï¼ˆDeepL API ã‚’åˆ©ç”¨ãƒ»ä»»æ„ï¼‰
- ã‚«ãƒ¼ãƒ‰UI / ã‚¿ãƒ– / KPI / ç›¸å¯¾æ™‚åˆ»
- ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆgeneral: trueï¼‰ã¯ AIã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ãƒ’ãƒƒãƒˆã—ãŸã‚‚ã®ã ã‘æ¡ç”¨
- æœŸé–“: HOURS_LOOKBACK(æ—¢å®š24h) / ä»¶æ•°: MAX_ITEMS_PER_CATEGORY(æ—¢å®š8)
- ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: string.Templateï¼ˆJS/CSSã®{}è¡çªå›é¿ï¼‰
"""
from datetime import datetime, timedelta, timezone
from urllib.parse import urlparse
from string import Template
import os, re, sys, html, json, hashlib, time
import yaml, feedparser

# ===== åŸºæœ¬è¨­å®š =====
JST = timezone(timedelta(hours=9))
HOURS_LOOKBACK = int(os.environ.get("HOURS_LOOKBACK", "24"))
MAX_ITEMS_PER_CATEGORY = int(os.environ.get("MAX_ITEMS_PER_CATEGORY", "8"))

# æ—¥æœ¬èªè¦ç´„ã‚’ç”Ÿæˆã™ã‚‹ã‹ï¼ˆDEEPL_API_KEY ãŒå¿…è¦ï¼‰
TRANSLATE_TO_JA = os.environ.get("TRANSLATE_TO_JA", "0").lower() in ("1","true","yes")
DEEPL_API_KEY = os.environ.get("DEEPL_API_KEY", "")

# ===== AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ =====
KEYWORDS_COMMON = [
    "AI","äººå·¥çŸ¥èƒ½","ç”ŸæˆAI","ç”Ÿæˆå‹AI","å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«","LLM","æ©Ÿæ¢°å­¦ç¿’","æ·±å±¤å­¦ç¿’",
    "chatgpt","gpt","openai","anthropic","claude","llama","gemini","copilot",
    "stable diffusion","midjourney","mistral","cohere","perplexity","hugging face","langchain",
    "rag","ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯","æ¨è«–","å¾®èª¿æ•´","ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°","ç”»åƒç”Ÿæˆ","å‹•ç”»ç”Ÿæˆ","sora","nemo","nim","blackwell"
]
KEYWORDS_BUSINESS = [
    "è¦åˆ¶","æ³•è¦åˆ¶","ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³","æ”¿åºœ","çœåº","æŠ•è³‡","è³‡é‡‘èª¿é”","ipo","è²·å","m&a",
    "ææº","åˆæ„","ä¾¡æ ¼","æ–™é‡‘","ä¼æ¥­å°å…¥","å•†ç”¨åˆ©ç”¨","å¸‚å ´","å£²ä¸Š","åç›Š","é›‡ç”¨","ç›£ç£","è¦åˆ¶å½“å±€","ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹"
]
KEYWORDS_TOOLS = [
    "api","sdk","ãƒ¢ãƒ‡ãƒ«","ãƒªãƒªãƒ¼ã‚¹","ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ","ãƒ™ãƒ¼ã‚¿","ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼","ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹","oss",
    "ã‚µãƒ³ãƒ—ãƒ«","ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«","ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸","ãƒ©ã‚¤ãƒ–ãƒ©ãƒª","ãƒãƒ¼ã‚¸ãƒ§ãƒ³","benchmark","throughput","latency","æ€§èƒ½","æ¨è«–é€Ÿåº¦"
]
NEGATIVE_HINTS = ["ã‚¹ãƒãƒ¼ãƒ„","å¤©æ°—","ç‚ºæ›¿","ç›¸å ´","è¦³å…‰","ãƒ¬ã‚·ãƒ”","å ã„"]

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def strip_tags(s: str) -> str:
    if not s: return ""
    s = re.sub(r"<[^>]+>", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def humanize(dt: datetime, now: datetime) -> str:
    delta = now - dt
    sec = int(delta.total_seconds())
    if sec < 60:   return "ãŸã£ãŸä»Š"
    if sec < 3600: return f"{sec // 60}åˆ†å‰"
    if sec < 86400:return f"{sec // 3600}æ™‚é–“å‰"
    days = sec // 86400
    return f"{days}æ—¥å‰"

def parse_dt(entry):
    for key in ("published_parsed", "updated_parsed"):
        t = getattr(entry, key, None) or entry.get(key)
        if t:
            return datetime(*t[:6], tzinfo=timezone.utc).astimezone(JST)
    return None

def domain_of(link: str) -> str:
    try:
        host = urlparse(link).netloc
        return host.replace("www.", "")
    except Exception:
        return ""

def normalize_feeds(feeds_yaml: dict) -> dict:
    norm = {"business": [], "tools": [], "posts": []}
    for k, v in (feeds_yaml or {}).items():
        lk = (k or "").strip().lower()
        if lk in norm:
            norm[lk] = v or []
    for old, new in (("Business","business"),("Tools","tools"),("Posts","posts")):
        if old in (feeds_yaml or {}):
            norm[new] = feeds_yaml.get(old) or norm[new]
    return norm

def matches_keywords(text: str, keywords: list[str]) -> bool:
    s = text.lower()
    for kw in keywords:
        if kw.lower() in s:
            return True
    return False

# ===== ç¿»è¨³ï¼ˆDeepLï¼‰ï¼‹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ =====
def _cache_path():
    os.makedirs("_cache", exist_ok=True)
    return os.path.join("_cache", "translations.json")

def _load_cache():
    try:
        with open(_cache_path(), "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def _save_cache(cache: dict):
    with open(_cache_path(), "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

def translate_to_ja(text: str) -> str | None:
    """DeepL APIã§æ—¥æœ¬èªè¨³ã€‚ã‚­ãƒ¼æœªè¨­å®šã‚„å¤±æ•—æ™‚ã¯ None ã‚’è¿”ã™ã€‚"""
    if not (TRANSLATE_TO_JA and DEEPL_API_KEY and text):
        return None
    h = hashlib.sha1(text.encode("utf-8")).hexdigest()
    cache = _load_cache()
    if h in cache:
        return cache[h]
    try:
        import deepl
        translator = deepl.Translator(DEEPL_API_KEY)
        # æ–‡ç« ãŒé•·ã„å ´åˆã¯é©åº¦ã«åˆ‡ã‚‹ï¼ˆã‚³ã‚¹ãƒˆæŠ‘åˆ¶ï¼‰
        src = text[:1200]
        ja = translator.translate_text(src, target_lang="JA").text
        cache[h] = ja
        _save_cache(cache)
        time.sleep(0.2)  # ãƒ¬ãƒ¼ãƒˆæ§ãˆã‚
        return ja
    except Exception as e:
        print(f"[WARN] DeepL translation failed: {e}", file=sys.stderr)
        return None

# ===== åé›†ï¼ˆAIãƒ•ã‚£ãƒ«ã‚¿ï¼‹æ—¥æœ¬èªè¦ç´„ï¼‰ =====
def collect(feeds_cfg: dict) -> dict:
    cutoff = datetime.now(JST) - timedelta(hours=HOURS_LOOKBACK)
    result = {"business": [], "tools": [], "posts": []}
    seen_links = set()

    for cat in result.keys():
        for item in feeds_cfg.get(cat, []):
            if isinstance(item, dict):
                name = item.get("name") or ""
                url  = item.get("url") or ""
                is_general = bool(item.get("general", False))
                include_extra = item.get("include") or []
            else:
                name, url, is_general, include_extra = "", str(item), False, []

            try:
                parsed = feedparser.parse(url)
            except Exception as e:
                print(f"[WARN] parse error: {url} -> {e}", file=sys.stderr)
                continue

            if cat == "business":
                kw = KEYWORDS_COMMON + KEYWORDS_BUSINESS + include_extra
            elif cat == "tools":
                kw = KEYWORDS_COMMON + KEYWORDS_TOOLS + include_extra
            else:
                kw = KEYWORDS_COMMON + include_extra

            for e in parsed.entries:
                dt = parse_dt(e) or datetime.now(JST)
                if dt < cutoff:
                    continue

                title = getattr(e, "title", "(no title)")
                link  = getattr(e, "link", "#")
                summary_raw = getattr(e, "summary", "")
                text = f"{title} {strip_tags(summary_raw)}"

                if is_general:
                    if any(neg in text for neg in NEGATIVE_HINTS):
                        continue
                    if not matches_keywords(text, kw):
                        continue

                if link in seen_links:
                    continue
                seen_links.add(link)

                # è‹±èªãƒ™ãƒ¼ã‚¹ã®è¦ç´„ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ã«è¦ç´„ãŒç„¡ã„å ´åˆã¯ã‚¿ã‚¤ãƒˆãƒ«ï¼‰
                en_summary = strip_tags(summary_raw) or title
                if len(en_summary) > 220:
                    en_summary = en_summary[:220] + "â€¦"

                ja_summary = translate_to_ja(en_summary)
                if ja_summary:
                    summary = html.escape(ja_summary)
                    lang = "ja"
                else:
                    summary = html.escape(en_summary)  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯è‹±èª
                    lang = "en"

                result[cat].append({
                    "title": html.escape(title),
                    "link": link,
                    "summary": summary,
                    "dt": dt,
                    "source": name or domain_of(link),
                    "lang": lang,
                })

    for cat in result:
        result[cat].sort(key=lambda x: x["dt"], reverse=True)
        result[cat] = result[cat][:MAX_ITEMS_PER_CATEGORY]
    return result

# ===== HTMLãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° =====
PAGE_TMPL = Template("""<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Daily AI News â€” ${updated}</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <header class="site-header">
    <div class="brand">ğŸ“° Daily AI News</div>
    <div class="updated">æœ€çµ‚æ›´æ–°ï¼š${updated}</div>
  </header>

  <main class="container">
    <h1 class="page-title">ä»Šæ—¥ã®æœ€æ–°AIæƒ…å ±</h1>
    <p class="lead">ãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒ„ãƒ¼ãƒ«æƒ…å ±ãƒ»SNS/è«–æ–‡ãƒã‚¹ãƒˆã«åˆ†ã‘ã€ç›´è¿‘${hours}æ™‚é–“ã®æ›´æ–°ã‚’é…ä¿¡ã—ã¾ã™ã€‚ã‚½ãƒ¼ã‚¹ã¯åŸæ–‡ï¼ˆè‹±èªç­‰ï¼‰ã®ã¾ã¾ã€è¦ç´„ã®ã¿æ—¥æœ¬èªåŒ–ã€‚</p>

    <section class="kpi-grid">
      <div class="kpi-card">
        <div class="kpi-value">${n_business}ä»¶</div>
        <div class="kpi-label">ãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹</div>
        <div class="kpi-note">é‡è¦åº¦é«˜ã‚</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-value">${n_tools}ä»¶</div>
        <div class="kpi-label">ãƒ„ãƒ¼ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹</div>
        <div class="kpi-note">é–‹ç™ºè€…å‘ã‘</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-value">${n_posts}ä»¶</div>
        <div class="kpi-label">SNS/è«–æ–‡ãƒã‚¹ãƒˆ</div>
        <div class="kpi-note">æ¤œè¨¼ç³»</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-value">${date_jst}</div>
        <div class="kpi-label">æœ€çµ‚æ›´æ–°</div>
        <div class="kpi-note">JST</div>
      </div>
    </section>

    <nav class="tabs" role="tablist">
      <button class="tab active" data-target="#business" aria-selected="true">ğŸ¢ ãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹</button>
      <button class="tab" data-target="#tools" aria-selected="false">âš¡ ãƒ„ãƒ¼ãƒ«ãƒ‹ãƒ¥ãƒ¼ã‚¹</button>
      <button class="tab" data-target="#posts" aria-selected="false">ğŸ§ª SNS/è«–æ–‡ãƒã‚¹ãƒˆ</button>
    </nav>

    ${sections}

    <section class="note">
      <p>æ–¹é‡ï¼šä¸€æ¬¡æƒ…å ±ï¼ˆå…¬å¼ãƒ–ãƒ­ã‚°/ãƒ—ãƒ¬ã‚¹/è«–æ–‡ï¼‰ã‚’å„ªå…ˆã€‚ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ AI ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æŠ½å‡ºã€‚è¦ç´„ã¯æ—¥æœ¬èªåŒ–ã—ã€<strong>å‡ºå…¸ãƒªãƒ³ã‚¯ã¯åŸæ–‡</strong>ã®ã¾ã¾ã€‚</p>
    </section>
  </main>

  <footer class="site-footer">
    <div>Generated by <code>build.py</code> Â· Timezone: JST</div>
    <div><a href="https://github.com/">Hosted on GitHub Pages</a></div>
  </footer>

  <script>
    const tabs = document.querySelectorAll('.tab');
    tabs.forEach(btn => btn.addEventListener('click', () => {
      tabs.forEach(b => { b.classList.remove('active'); b.setAttribute('aria-selected','false'); });
      btn.classList.add('active'); btn.setAttribute('aria-selected','true');
      document.querySelectorAll('.tab-panel').forEach(p => p.classList.add('hidden'));
      const target = document.querySelector(btn.dataset.target);
      if (target) target.classList.remove('hidden');
    }));
  </script>
</body>
</html>""")

SECTION_TMPL = Template("""
<section id="${id}" class="tab-panel ${hidden}">
  ${cards}
</section>""")

CARD_TMPL = Template("""
<article class="card">
  <div class="card-header">
    <a class="card-title" href="${link}" target="_blank" rel="noopener">${title}</a>
  </div>
  <div class="card-body">
    <p class="card-summary">${summary}</p>
    <div class="chips">
      <span class="chip">${source}</span>
      <span class="chip ghost">${langlabel}</span>
      <span class="chip ghost">${timeago}</span>
    </div>
  </div>
  <div class="card-footer">
    å‡ºå…¸: <a href="${link}" target="_blank" rel="noopener">${link}</a>
  </div>
</article>""")

EMPTY_TMPL = '<div class="empty">æ–°ç€ãªã—ï¼ˆæœŸé–“ã‚’åºƒã’ã‚‹ã‹ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼‰</div>'

def render_cards(items, now) -> str:
    if not items:
        return EMPTY_TMPL
    htmls = []
    for it in items:
        langlabel = "è¦ç´„: æ—¥æœ¬èª" if it.get("lang") == "ja" else "è¦ç´„: è‹±èª"
        htmls.append(CARD_TMPL.substitute(
            link=it["link"],
            title=it["title"],
            summary=it["summary"],
            source=html.escape(it["source"] or ""),
            langlabel=langlabel,
            timeago=humanize(it["dt"], now),
        ))
    return "\n".join(htmls)

def render_page(collected: dict) -> str:
    now = datetime.now(JST)
    sections = []
    sections.append(SECTION_TMPL.substitute(id="business", hidden="", cards=render_cards(collected["business"], now)))
    sections.append(SECTION_TMPL.substitute(id="tools", hidden="hidden", cards=render_cards(collected["tools"], now)))
    sections.append(SECTION_TMPL.substitute(id="posts", hidden="hidden", cards=render_cards(collected["posts"], now)))
    return PAGE_TMPL.substitute(
        updated=now.strftime("%Y-%m-%d %H:%M JST"),
        hours=HOURS_LOOKBACK,
        n_business=len(collected["business"]),
        n_tools=len(collected["tools"]),
        n_posts=len(collected["posts"]),
        date_jst=now.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M"),
        sections="\n".join(sections)
    )

def main():
    with open("feeds.yml", "r", encoding="utf-8") as f:
        raw = yaml.safe_load(f) or {}
    feeds = normalize_feeds(raw)
    data = collect(feeds)
    html_out = render_page(data)
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_out)
    print("wrote index.html")

if __name__ == "__main__":
    main()
