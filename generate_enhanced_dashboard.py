#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‹¡å¼µAIãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ  + Webåˆ†æ + XæŠ•ç¨¿ã‚’çµ±åˆã—ã€æƒ…å ±é‡ã‚’æœ€å¤§åŒ–
"""

import json
import os
import csv
import requests
import yaml
import feedparser
from datetime import datetime, timedelta
from pathlib import Path
import sys
import re

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    os.environ[key.strip()] = value.strip()

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def fetch_x_posts():
    """XæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’Google Sheetsã‹ã‚‰å–å¾—ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    csv_url = os.getenv('X_POSTS_CSV', 'https://docs.google.com/spreadsheets/d/1uuLKCLIJw--a1vCcO6UGxSpBiLTtN8uGl2cdMb6wcfg/export?format=csv&gid=0')
    
    try:
        print("ğŸ“± XæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        # User-Agentã‚’è¨­å®šã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(csv_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # CSVãƒ‡ãƒ¼ã‚¿ã‚’è§£æ
        lines = response.text.strip().split('\n')
        if len(lines) < 2:
            print("âš ï¸ CSVãƒ‡ãƒ¼ã‚¿ãŒç©ºã¾ãŸã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã®ã¿ã§ã™")
            return []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ç¢ºèª
        header_line = lines[0]
        print(f"ğŸ“‹ CSVãƒ˜ãƒƒãƒ€ãƒ¼: {header_line}")
        
        csv_reader = csv.DictReader(lines)
        
        posts = []
        for i, row in enumerate(csv_reader):
            # è¡Œã®å†…å®¹ã‚’ç¢ºèª
            if i < 3:  # æœ€åˆã®3è¡Œã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
                print(f"ğŸ” è¡Œ {i+1}: {dict(row)}")
            
            # æ§˜ã€…ãªå¯èƒ½æ€§ã®ã‚ã‚‹ã‚«ãƒ©ãƒ åã‚’è©¦è¡Œ
            content_keys = ['æŠ•ç¨¿å†…å®¹', 'content', 'Content', 'Tweet', 'Text', 'Post']
            author_keys = ['ãƒ¦ãƒ¼ã‚¶ãƒ¼å', 'username', 'Username', 'Author', 'User', 'author']
            likes_keys = ['ã„ã„ã­æ•°', 'likes', 'Likes', 'Like', 'Hearts']
            retweets_keys = ['ãƒªãƒã‚¹ãƒˆæ•°', 'retweets', 'Retweets', 'RT', 'Shares']
            
            content = None
            author = 'ä¸æ˜'
            likes = 0
            retweets = 0
            
            # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ¢ã™
            for key in content_keys:
                if key in row and row[key] and row[key].strip():
                    content = row[key].strip()
                    break
            
            # è‘—è€…ã‚’æ¢ã™
            for key in author_keys:
                if key in row and row[key] and row[key].strip():
                    author = row[key].strip()
                    break
            
            # ã„ã„ã­æ•°ã‚’æ¢ã™
            for key in likes_keys:
                if key in row and row[key]:
                    try:
                        likes = int(row[key].replace(',', ''))
                        break
                    except (ValueError, TypeError):
                        pass
            
            # ãƒªãƒ„ã‚¤ãƒ¼ãƒˆæ•°ã‚’æ¢ã™
            for key in retweets_keys:
                if key in row and row[key]:
                    try:
                        retweets = int(row[key].replace(',', ''))
                        break
                    except (ValueError, TypeError):
                        pass
            
            if content and len(content) > 10:  # æœ‰åŠ¹ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ã‚‹å ´åˆã®ã¿è¿½åŠ 
                posts.append({
                    'content': content,
                    'author': author,
                    'likes': likes,
                    'retweets': retweets,
                    'timestamp': row.get('æŠ•ç¨¿æ—¥æ™‚', row.get('timestamp', row.get('Date', ''))),
                    'url': row.get('URL', row.get('url', ''))
                })
        
        print(f"âœ… XæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(posts)}ä»¶")
        
        # æŠ•ç¨¿å†…å®¹ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤º
        if posts:
            print("ğŸ“„ å–å¾—ã•ã‚ŒãŸæŠ•ç¨¿ä¾‹:")
            for i, post in enumerate(posts[:3]):
                print(f"   {i+1}. {post['content'][:50]}... (ğŸ‘¤{post['author']} â¤ï¸{post['likes']})")
        
        return posts
        
    except Exception as e:
        print(f"âŒ XæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ğŸ”— è©¦è¡ŒURL: {csv_url}")
        return []

def fetch_existing_rss_feeds():
    """æ—¢å­˜ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰è¨­å®šã‹ã‚‰è¿½åŠ æƒ…å ±ã‚’å–å¾—"""
    feeds_file = 'feeds.yml'
    if not os.path.exists(feeds_file):
        print("âš ï¸ feeds.ymlãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []
    
    try:
        print("ğŸ“¡ æ—¢å­˜RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰è¿½åŠ ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        with open(feeds_file, 'r', encoding='utf-8') as f:
            feeds_config = yaml.safe_load(f)
        
        hours_lookback = int(os.getenv('HOURS_LOOKBACK', 24))
        cutoff_time = datetime.now() - timedelta(hours=hours_lookback)
        
        additional_items = []
        
        for category, feeds in feeds_config.items():
            if isinstance(feeds, list):
                for feed_url in feeds[:2]:  # å„ã‚«ãƒ†ã‚´ãƒªä¸Šä½2ãƒ•ã‚£ãƒ¼ãƒ‰
                    try:
                        print(f"ğŸ“¡ {category}: {feed_url}")
                        feed = feedparser.parse(feed_url)
                        
                        for entry in feed.entries[:3]:  # å„ãƒ•ã‚£ãƒ¼ãƒ‰3ä»¶
                            # æ—¥æ™‚ãƒã‚§ãƒƒã‚¯
                            entry_time = None
                            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                                entry_time = datetime(*entry.published_parsed[:6])
                            elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                                entry_time = datetime(*entry.updated_parsed[:6])
                            
                            if entry_time and entry_time > cutoff_time:
                                additional_items.append({
                                    'title': entry.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—'),
                                    'summary': entry.get('summary', entry.get('description', ''))[:200],
                                    'link': entry.get('link', ''),
                                    'category': category,
                                    'published': entry_time.strftime('%Y-%m-%d %H:%M') if entry_time else '',
                                    'source': 'RSS Feed'
                                })
                    except Exception as e:
                        print(f"âš ï¸ RSSå–å¾—ã‚¨ãƒ©ãƒ¼ ({feed_url}): {e}")
                        continue
        
        print(f"âœ… RSSè¿½åŠ ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(additional_items)}ä»¶")
        return additional_items
        
    except Exception as e:
        print(f"âŒ RSSè¨­å®šèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def extract_trending_topics(web_data, x_posts, rss_items):
    """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º"""
    trending_keywords = {}
    
    # Webåˆ†æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    for category, articles in web_data.items():
        for article in articles:
            ai_analysis = article.get('ai_analysis', {})
            if 'keywords' in ai_analysis and ai_analysis['keywords'].get('success'):
                keywords_data = ai_analysis['keywords']
                if 'primary_keywords' in keywords_data:
                    for keyword in keywords_data['primary_keywords']:
                        trending_keywords[keyword] = trending_keywords.get(keyword, 0) + 2
    
    # XæŠ•ç¨¿ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    ai_terms = ['AI', 'GPT', 'Claude', 'Gemini', 'ChatGPT', 'OpenAI', 'Anthropic', 'Google', 'Microsoft', 
                'äººå·¥çŸ¥èƒ½', 'LLM', 'ML', 'æ©Ÿæ¢°å­¦ç¿’', 'ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°', 'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«']
    
    for post in x_posts:
        content = post['content'].upper()
        for term in ai_terms:
            if term.upper() in content:
                trending_keywords[term] = trending_keywords.get(term, 0) + 1
    
    # RSSã‚¢ã‚¤ãƒ†ãƒ ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    for item in rss_items:
        title_summary = (item['title'] + ' ' + item['summary']).upper()
        for term in ai_terms:
            if term.upper() in title_summary:
                trending_keywords[term] = trending_keywords.get(term, 0) + 1
    
    return sorted(trending_keywords.items(), key=lambda x: x[1], reverse=True)[:10]

def generate_enhanced_dashboard(analysis_file: str = None):
    """æ‹¡å¼µãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ"""
    
    # å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å–å¾—
    web_data = {}
    if analysis_file and os.path.exists(analysis_file):
        with open(analysis_file, 'r', encoding='utf-8') as f:
            web_data = json.load(f)
    
    x_posts = fetch_x_posts()
    rss_items = fetch_existing_rss_feeds()
    trending_topics = extract_trending_topics(web_data, x_posts, rss_items)
    
    # çµ±è¨ˆè¨ˆç®—
    total_web_articles = sum(len(articles) for articles in web_data.values())
    total_sources = len(web_data) + (1 if x_posts else 0) + (1 if rss_items else 0)
    
    timestamp = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %Hæ™‚%Måˆ†')
    
    # HTMLç”Ÿæˆ
    html = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AIæ¥­ç•Œç·åˆã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹ | {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}
        
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }}
        
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            padding: 20px;
        }}
        
        .header {{
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 30px;
            text-align: center;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
        }}
        
        .header h1 {{
            font-size: 3rem;
            background: linear-gradient(45deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 10px;
        }}
        
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }}
        
        .stat-card {{
            background: rgba(255, 255, 255, 0.9);
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            backdrop-filter: blur(5px);
            transition: transform 0.3s ease;
        }}
        
        .stat-card:hover {{
            transform: translateY(-5px);
        }}
        
        .stat-number {{
            font-size: 2.5rem;
            font-weight: bold;
            color: #667eea;
        }}
        
        .stat-label {{
            font-size: 1rem;
            color: #666;
            margin-top: 5px;
        }}
        
        .sections {{
            display: grid;
            gap: 30px;
        }}
        
        .section {{
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            overflow: hidden;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            backdrop-filter: blur(10px);
        }}
        
        .section-header {{
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 20px;
            font-size: 1.5rem;
            font-weight: bold;
        }}
        
        .section-content {{
            padding: 20px;
        }}
        
        .insight-item {{
            border-bottom: 1px solid #eee;
            padding: 20px 0;
            transition: all 0.3s ease;
        }}
        
        .insight-item:last-child {{
            border-bottom: none;
        }}
        
        .insight-item:hover {{
            background: rgba(102, 126, 234, 0.05);
            border-radius: 10px;
            margin: 0 -10px;
            padding: 20px 10px;
        }}
        
        .insight-title {{
            font-size: 1.3rem;
            font-weight: bold;
            color: #333;
            margin-bottom: 10px;
            line-height: 1.4;
        }}
        
        .insight-description {{
            color: #666;
            line-height: 1.6;
            margin-bottom: 15px;
        }}
        
        .insight-meta {{
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            font-size: 0.9rem;
            color: #888;
        }}
        
        .trending-topics {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 15px;
        }}
        
        .topic-card {{
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 15px;
            border-radius: 10px;
            text-align: center;
            font-weight: bold;
        }}
        
        .topic-count {{
            font-size: 1.5rem;
            margin-bottom: 5px;
        }}
        
        .x-posts {{
            display: grid;
            gap: 15px;
        }}
        
        .x-post {{
            background: rgba(29, 161, 242, 0.1);
            border-left: 4px solid #1da1f2;
            padding: 20px;
            border-radius: 0 10px 10px 0;
            transition: all 0.3s ease;
        }}
        
        .x-post:hover {{
            background: rgba(29, 161, 242, 0.15);
            transform: translateX(5px);
        }}
        
        .post-content {{
            font-size: 1rem;
            line-height: 1.5;
            margin-bottom: 10px;
        }}
        
        .post-meta {{
            display: flex;
            justify-content: space-between;
            font-size: 0.9rem;
            color: #666;
        }}
        
        .engagement {{
            display: flex;
            gap: 15px;
        }}
        
        .rss-items {{
            display: grid;
            gap: 15px;
        }}
        
        .rss-item {{
            background: rgba(102, 126, 234, 0.1);
            border-left: 4px solid #667eea;
            padding: 20px;
            border-radius: 0 10px 10px 0;
            transition: all 0.3s ease;
        }}
        
        .rss-item:hover {{
            background: rgba(102, 126, 234, 0.15);
            transform: translateX(5px);
        }}
        
        @media (max-width: 768px) {{
            .stats {{
                grid-template-columns: repeat(2, 1fr);
            }}
            
            .header h1 {{
                font-size: 2rem;
            }}
        }}
        
        .timestamp {{
            color: #888;
            font-size: 0.9rem;
            margin-top: 10px;
            text-align: center;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ AIæ¥­ç•Œç·åˆã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹</h1>
            <p>Webåˆ†æ Ã— XæŠ•ç¨¿ Ã— RSSé…ä¿¡ã®çµ±åˆæƒ…å ±ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰</p>
            <div class="timestamp">æœ€çµ‚æ›´æ–°: {timestamp}</div>
        </div>
        
        <div class="stats">
            <div class="stat-card">
                <div class="stat-number">{total_web_articles}</div>
                <div class="stat-label">Webè¨˜äº‹åˆ†æ</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">{len(x_posts)}</div>
                <div class="stat-label">XæŠ•ç¨¿ç›£è¦–</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">{len(rss_items)}</div>
                <div class="stat-label">RSSé…ä¿¡</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">{total_sources}</div>
                <div class="stat-label">ç·åˆãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹</div>
            </div>
        </div>
        
        <div class="sections">
"""
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒˆãƒ”ãƒƒã‚¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if trending_topics:
        html += f"""
            <div class="section">
                <div class="section-header">
                    ğŸ”¥ ãƒˆãƒ¬ãƒ³ãƒ‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                </div>
                <div class="section-content">
                    <div class="trending-topics">
        """
        
        for keyword, count in trending_topics[:8]:
            html += f"""
                        <div class="topic-card">
                            <div class="topic-count">{count}</div>
                            <div>{keyword}</div>
                        </div>
            """
        
        html += """
                    </div>
                </div>
            </div>
        """
    
    # Webåˆ†æã‚¤ãƒ³ã‚µã‚¤ãƒˆ
    if web_data:
        html += f"""
            <div class="section">
                <div class="section-header">
                    ğŸŒ é‡è¦Webåˆ†æçµæœ ({total_web_articles}ä»¶)
                </div>
                <div class="section-content">
        """
        
        category_names = {
            'ai_breaking_news': 'ğŸ”¥ AIæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹',
            'ai_research_labs': 'ğŸ§ª AIç ”ç©¶ãƒ©ãƒœ',
            'business_startup': 'ğŸ’¼ ãƒ“ã‚¸ãƒã‚¹ãƒ»ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—',
            'tech_innovation': 'âš¡ æŠ€è¡“é©æ–°',
            'policy_regulation': 'ğŸ“œ æ”¿ç­–ãƒ»è¦åˆ¶',
            'academic_research': 'ğŸ“ å­¦è¡“ç ”ç©¶'
        }
        
        for category, articles in web_data.items():
            category_name = category_names.get(category, category)
            
            for article in articles[:2]:  # å„ã‚«ãƒ†ã‚´ãƒªä¸Šä½2ä»¶
                basic = article.get('basic', {})
                ai_analysis = article.get('ai_analysis', {})
                
                title = basic.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')
                
                # AIè¦ç´„å–å¾—
                summary_text = "ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã®é«˜ã„æƒ…å ±ãŒç¢ºèªã•ã‚Œã¾ã—ãŸ"
                if 'summary' in ai_analysis and ai_analysis['summary'].get('success'):
                    summary_data = ai_analysis['summary']
                    if 'summary' in summary_data:
                        summary_text = summary_data['summary'][:200]
                    elif 'raw_response' in summary_data:
                        summary_text = summary_data['raw_response'][:200]
                
                html += f"""
                    <div class="insight-item">
                        <div class="insight-title">{title}</div>
                        <div class="insight-description">{summary_text}...</div>
                        <div class="insight-meta">
                            <span>ğŸ“‚ {category_name}</span>
                            <span>ğŸ¤– AIåˆ†ææ¸ˆã¿</span>
                        </div>
                    </div>
                """
        
        html += """
                </div>
            </div>
        """
    
    # XæŠ•ç¨¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if x_posts:
        html += f"""
            <div class="section">
                <div class="section-header">
                    ğŸ“± æ³¨ç›®XæŠ•ç¨¿ ({len(x_posts)}ä»¶)
                </div>
                <div class="section-content">
                    <div class="x-posts">
        """
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé †ã§ã‚½ãƒ¼ãƒˆ
        sorted_posts = sorted(x_posts, key=lambda x: x['likes'] + x['retweets'], reverse=True)
        
        for post in sorted_posts[:8]:  # ä¸Šä½8æŠ•ç¨¿
            html += f"""
                        <div class="x-post">
                            <div class="post-content">{post['content']}</div>
                            <div class="post-meta">
                                <span>ğŸ‘¤ {post['author']}</span>
                                <div class="engagement">
                                    <span>â¤ï¸ {post['likes']:,}</span>
                                    <span>ğŸ”„ {post['retweets']:,}</span>
                                </div>
                            </div>
                        </div>
            """
        
        html += """
                    </div>
                </div>
            </div>
        """
    
    # RSSè¿½åŠ æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if rss_items:
        html += f"""
            <div class="section">
                <div class="section-header">
                    ğŸ“¡ æœ€æ–°RSSé…ä¿¡ ({len(rss_items)}ä»¶)
                </div>
                <div class="section-content">
                    <div class="rss-items">
        """
        
        for item in rss_items[:10]:  # ä¸Šä½10ä»¶
            html += f"""
                        <div class="rss-item">
                            <div class="insight-title">{item['title']}</div>
                            <div class="insight-description">{item['summary']}...</div>
                            <div class="insight-meta">
                                <span>ğŸ“‚ {item['category']}</span>
                                <span>ğŸ“… {item['published']}</span>
                                <span>ğŸ“¡ {item['source']}</span>
                            </div>
                        </div>
            """
        
        html += """
                    </div>
                </div>
            </div>
        """
    
    html += """
        </div>
        
        <div class="timestamp">
            æ¬¡å›æ›´æ–°: 24æ™‚é–“å¾Œï¼ˆè‡ªå‹•ï¼‰ | ã“ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¯è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ
        </div>
    </div>
</body>
</html>"""
    
    return html

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    # æœ€æ–°ã®åˆ†æãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    analysis_files = list(Path('.').glob('comprehensive_analysis_*.json'))
    latest_file = None
    
    if analysis_files:
        latest_file = max(analysis_files, key=lambda f: f.stat().st_mtime)
        print(f"ğŸ“Š Webåˆ†æãƒ‡ãƒ¼ã‚¿: {latest_file}")
    else:
        print("âš ï¸ Webåˆ†æãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ
    html = generate_enhanced_dashboard(str(latest_file) if latest_file else None)
    
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f"enhanced_dashboard_{timestamp}.html"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html)
    
    print(f"âœ… æ‹¡å¼µãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†: {output_file}")
    
    # ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ã
    import webbrowser
    webbrowser.open(f"file://{os.path.abspath(output_file)}")
    
    print(f"ğŸŒ ãƒ–ãƒ©ã‚¦ã‚¶ã§æ‹¡å¼µãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’é–‹ãã¾ã—ãŸ")

if __name__ == "__main__":
    main()