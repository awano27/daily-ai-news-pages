#!/usr/bin/env python3
"""
æŠœæœ¬çš„403ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã®ãƒ†ã‚¹ãƒˆ
"""
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
os.chdir(r"C:\Users\yoshitaka\daily-ai-news")

try:
    print("ğŸ”§ æŠœæœ¬çš„403ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚’ãƒ†ã‚¹ãƒˆä¸­...")
    print("ğŸ“¡ æ–°æ©Ÿèƒ½:")
    print("  âœ… é«˜åº¦ãªHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶å¾¡ (requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒª)")
    print("  âœ… è¤‡æ•°User-Agentãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³")
    print("  âœ… Googleå°‚ç”¨ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š")
    print("  âœ… ãƒ©ãƒ³ãƒ€ãƒ é…å»¶ã«ã‚ˆã‚‹ãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿")
    print("  âœ… Reddit, Hacker News, GitHub Trendingç­‰ã®ä»£æ›¿ã‚½ãƒ¼ã‚¹")
    
    import build
    import yaml
    
    # feeds.ymlã‚’èª­ã¿è¾¼ã¿
    with open('feeds.yml', 'r', encoding='utf-8') as f:
        feeds_config = yaml.safe_load(f)
    
    # ç‰¹ã«Google Newsã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ¯ Google Newsã«å¯¾ã™ã‚‹ç‰¹åˆ¥ãªãƒ†ã‚¹ãƒˆ:")
    google_feeds = []
    for category, feeds in feeds_config.items():
        for feed in feeds:
            if 'google.com' in feed.get('url', '') or 'Google News' in feed.get('name', ''):
                google_feeds.append((feed, category))
                
    print(f"Found {len(google_feeds)} Google-related feeds")
    
    for feed, category in google_feeds[:2]:  # æœ€åˆã®2ã¤ã‚’ãƒ†ã‚¹ãƒˆ
        name = feed['name']
        url = feed['url']
        print(f"\nğŸ” Testing: {name}")
        
        # é«˜åº¦ãªãƒ•ã‚§ãƒƒãƒã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
        result = build.advanced_feed_fetch(url, name)
        if result:
            print(f"âœ… SUCCESS: {name} - Advanced fetch worked!")
            entries = len(result.entries) if hasattr(result, 'entries') else 0
            print(f"   Retrieved {entries} entries")
        else:
            print(f"âŒ FAILED: {name} - Advanced fetch failed")
    
    # æ–°ã—ã„ä»£æ›¿ã‚½ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ
    print("\nğŸ†• æ–°ã—ã„ä»£æ›¿ã‚½ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ:")
    alternative_sources = [
        'Hacker News', 'Reddit AI', 'AI Business News', 
        'Reddit MachineLearning', 'GitHub Trending', 'Reddit Science'
    ]
    
    success_count = 0
    total_count = 0
    
    for category, feeds in feeds_config.items():
        for feed in feeds:
            if feed['name'] in alternative_sources:
                total_count += 1
                print(f"Testing: {feed['name']}")
                try:
                    items = build.gather_items([feed], category)
                    if items:
                        success_count += 1
                        print(f"  âœ… SUCCESS: {len(items)} items")
                    else:
                        print(f"  âš ï¸ No items retrieved")
                except Exception as e:
                    print(f"  âŒ ERROR: {e}")
    
    print(f"\nğŸ“Š ä»£æ›¿ã‚½ãƒ¼ã‚¹æˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
    
    # å®Œå…¨ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ
    print("\nğŸ”„ å®Œå…¨ãªãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆãƒ†ã‚¹ãƒˆ...")
    from generate_comprehensive_dashboard import analyze_ai_landscape, generate_comprehensive_dashboard_html
    
    data = analyze_ai_landscape()
    html_content = generate_comprehensive_dashboard_html(data)
    
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_content)
    
    print("âœ… æŠœæœ¬çš„æ”¹å–„ç‰ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆå®Œäº†!")
    print(f"ğŸ“Š ç·ãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {data['stats']['total_items']}")
    print(f"ğŸ—£ï¸ SNSæŠ•ç¨¿æ•°: {data['x_posts']['total_count']}")
    
    # æ”¹å–„ã®ã‚µãƒãƒªãƒ¼
    print("\nğŸ‰ æŠœæœ¬çš„æ”¹å–„ã®åŠ¹æœ:")
    print("  ğŸ”§ è¤‡æ•°ã®User-Agentã§ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³")
    print("  ğŸŒ Googleå°‚ç”¨ã®HTTPãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š") 
    print("  â±ï¸ ãƒ¬ãƒ¼ãƒˆåˆ¶é™å›é¿ã®ãƒ©ãƒ³ãƒ€ãƒ é…å»¶")
    print("  ğŸ”„ ä»£æ›¿ã‚½ãƒ¼ã‚¹ã«ã‚ˆã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
    print("  ğŸ“¡ requests library ã«ã‚ˆã‚‹é«˜åº¦åˆ¶å¾¡")
    print("  ğŸ›¡ï¸ 403ã‚¨ãƒ©ãƒ¼è€æ€§ã®å¤§å¹…å‘ä¸Š")
    
except Exception as e:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    import traceback
    traceback.print_exc()