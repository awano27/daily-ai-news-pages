# -*- coding: utf-8 -*-
"""
Simple Enhanced Daily AI News - ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
å…ƒã® build.py ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€æƒ…å ±é‡ã‚’ç¶­æŒã—ã¤ã¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ©Ÿèƒ½ã‚’è¿½åŠ 

HTML Structure Fix Applied: 2025-08-23
- Enhanced card template with priority system
- Proper HTML tag structure and closure
- CSS generation included for styling
- Force GitHub Actions to use this updated version
"""

import os, re, sys, json, time, html, csv, io
from datetime import datetime, timezone, timedelta
from pathlib import Path
from urllib.parse import urlparse
from urllib.request import urlopen
import yaml
import feedparser
import requests
import random

# åŸºæœ¬è¨­å®š
HOURS_LOOKBACK = int(os.getenv('HOURS_LOOKBACK', '24'))
MAX_ITEMS_PER_CATEGORY = int(os.getenv('MAX_ITEMS_PER_CATEGORY', '25'))
TRANSLATE_TO_JA = os.getenv('TRANSLATE_TO_JA', '1') == '1'
TRANSLATE_ENGINE = os.getenv('TRANSLATE_ENGINE', 'google')
X_POSTS_CSV = os.getenv('X_POSTS_CSV', 'https://docs.google.com/spreadsheets/d/1uuLKCLIJw--a1vCcO6UGxSpBiLTtN8uGl2cdMb6wcfg/export?format=csv&gid=0')

# ç¿»è¨³æ©Ÿèƒ½
try:
    from deep_translator import GoogleTranslator, MyMemoryTranslator
    TRANSLATE_AVAILABLE = True
    print("âœ… ç¿»è¨³æ©Ÿèƒ½: åˆ©ç”¨å¯èƒ½")
except ImportError:
    print("âš ï¸ ç¿»è¨³æ©Ÿèƒ½: deep-translatoræœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
    TRANSLATE_AVAILABLE = False

class SimpleEngineerRanking:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é–¢é€£åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
    
    # ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡ã¿ä»˜ãï¼‰
    TECH_KEYWORDS = {
        # é«˜å„ªå…ˆåº¦ (3.0å€)
        'code': 3.0, 'api': 3.0, 'sdk': 3.0, 'github': 3.0, 'implementation': 3.0,
        'tutorial': 3.0, 'framework': 3.0, 'library': 3.0,
        
        # AI/ML (2.5å€)
        'pytorch': 2.5, 'tensorflow': 2.5, 'huggingface': 2.5, 'gpt': 2.5, 
        'llm': 2.5, 'openai': 2.5, 'anthropic': 2.5, 'model': 2.5, 'ai': 2.5,
        
        # ã‚¤ãƒ³ãƒ•ãƒ© (2.0å€)
        'docker': 2.0, 'kubernetes': 2.0, 'aws': 2.0, 'azure': 2.0, 'gcp': 2.0,
        'deployment': 2.0, 'production': 2.0, 'mlops': 2.0,
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (1.8å€)
        'performance': 1.8, 'benchmark': 1.8, 'optimization': 1.8, 'speed': 1.8,
        'memory': 1.8, 'gpu': 1.8, 'cuda': 1.8,
        
        # ç ”ç©¶ (1.5å€) 
        'research': 1.5, 'paper': 1.5, 'arxiv': 1.5, 'algorithm': 1.5,
        'method': 1.5, 'evaluation': 1.5
    }
    
    # ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹
    TRUSTED_DOMAINS = [
        'arxiv.org', 'github.com', 'pytorch.org', 'tensorflow.org', 
        'huggingface.co', 'openai.com', 'anthropic.com', 'deepmind.com',
        'ai.googleblog.com', 'research.facebook.com'
    ]
    
    @classmethod
    def calculate_score(cls, item):
        """ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®— (0-10)"""
        title = item.get('title', '').lower()
        summary = item.get('summary', '').lower()
        url = item.get('url', '').lower()
        
        content = f"{title} {summary}"
        score = 0.0
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for keyword, weight in cls.TECH_KEYWORDS.items():
            if keyword in content:
                score += weight
                # ã‚¿ã‚¤ãƒˆãƒ«ã«ã‚ã‚‹å ´åˆã¯è¿½åŠ ãƒœãƒ¼ãƒŠã‚¹
                if keyword in title:
                    score += weight * 0.5
        
        # ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹ãƒœãƒ¼ãƒŠã‚¹
        domain = urlparse(url).netloc.lower()
        for trusted in cls.TRUSTED_DOMAINS:
            if trusted in domain:
                score *= 1.3
                break
        
        # ã‚³ãƒ¼ãƒ‰ãƒ»å®Ÿè£…ã®ç‰¹åˆ¥ãƒœãƒ¼ãƒŠã‚¹
        if any(indicator in content for indicator in ['```', 'code example', 'implementation', 'github.com']):
            score *= 1.2
            
        # æ•°å€¤ãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒœãƒ¼ãƒŠã‚¹
        if re.search(r'\d+[%x]|\d+ms|\d+gb|benchmark', content):
            score *= 1.1
            
        return min(score, 10.0)
    
    @classmethod
    def get_priority(cls, score):
        """ã‚¹ã‚³ã‚¢ã‹ã‚‰å„ªå…ˆåº¦æƒ…å ±ã‚’å–å¾—"""
        if score >= 6.0:
            return "ğŸ”¥", "hot", "æœ€é«˜å„ªå…ˆ"
        elif score >= 4.0:
            return "âš¡", "high", "é«˜å„ªå…ˆ"
        elif score >= 2.5:
            return "ğŸ“–", "medium", "ä¸­å„ªå…ˆ"
        elif score >= 1.0:
            return "ğŸ“°", "low", "ä½å„ªå…ˆ"
        else:
            return "ğŸ“„", "minimal", "å‚è€ƒ"

def load_feeds():
    """ãƒ•ã‚£ãƒ¼ãƒ‰è¨­å®šã‚’èª­ã¿è¾¼ã¿ï¼ˆç°¡ç´ ç‰ˆï¼‰"""
    feeds_file = Path('feeds.yml')
    if not feeds_file.exists():
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            'Business': [
                'https://venturebeat.com/ai/feed/',
                'https://techcrunch.com/category/artificial-intelligence/feed/',
                'https://www.reddit.com/r/artificial/.rss'
            ],
            'Tools': [
                'https://huggingface.co/blog/feed.xml',
                'https://pytorch.org/blog/rss.xml',
                'https://www.reddit.com/r/MachineLearning/.rss'
            ],
            'Posts': []  # X/Twitter posts + arXiv papers
        }
    
    # æ—¢å­˜ã®feeds.ymlã‚’èª­ã¿è¾¼ã¿ã€URLå½¢å¼ã«å¤‰æ›
    with open(feeds_file, 'r', encoding='utf-8') as f:
        feeds_data = yaml.safe_load(f)
    
    processed_feeds = {}
    for category, feed_list in feeds_data.items():
        processed_feeds[category] = []
        for feed_entry in feed_list:
            if isinstance(feed_entry, dict) and 'url' in feed_entry:
                # ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ãªã„ã‚‚ã®ã®ã¿è¿½åŠ 
                if not feed_entry.get('disabled', False):
                    processed_feeds[category].append(feed_entry['url'])
            elif isinstance(feed_entry, str):
                processed_feeds[category].append(feed_entry)
    
    return processed_feeds

def fetch_articles():
    """è¨˜äº‹ã‚’å–å¾—ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
    feeds = load_feeds()
    all_items = []
    cutoff_time = datetime.now(timezone.utc) - timedelta(hours=HOURS_LOOKBACK)
    
    print(f"ğŸ“° è¨˜äº‹å–å¾—é–‹å§‹: {HOURS_LOOKBACK}æ™‚é–“ä»¥å†…ã€æœ€å¤§{MAX_ITEMS_PER_CATEGORY}ä»¶/ã‚«ãƒ†ã‚´ãƒª")
    
    for category, urls in feeds.items():
        if category == 'Posts':
            continue  # X posts + arXiv papersã¯å¾Œã§å‡¦ç†
            
        print(f"ğŸ“‚ {category}")
        category_items = []
        
        for url in urls[:10]:  # æœ€å¤§10ãƒ•ã‚£ãƒ¼ãƒ‰/ã‚«ãƒ†ã‚´ãƒª
            try:
                print(f"  ğŸ”„ {url}")
                feed = feedparser.parse(url)
                
                for entry in feed.entries[:MAX_ITEMS_PER_CATEGORY]:
                    pub_date = datetime.now(timezone.utc)
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        pub_date = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
                    
                    if pub_date < cutoff_time:
                        continue
                    
                    item = {
                        'title': entry.get('title', 'No title'),
                        'url': entry.get('link', ''),
                        'summary': clean_text(entry.get('summary', '')),
                        'published': pub_date,
                        'source': get_source_name(url),
                        'category': category,
                        'is_x_post': False
                    }
                    
                    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚³ã‚¢è¨ˆç®—
                    item['score'] = SimpleEngineerRanking.calculate_score(item)
                    icon, cls, text = SimpleEngineerRanking.get_priority(item['score'])
                    item['priority_icon'] = icon
                    item['priority_class'] = cls  
                    item['priority_text'] = text
                    
                    category_items.append(item)
                    
            except Exception as e:
                print(f"    âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ã‚«ãƒ†ã‚´ãƒªå†…ã§ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆ
        category_items.sort(key=lambda x: x['score'], reverse=True)
        all_items.extend(category_items[:MAX_ITEMS_PER_CATEGORY])
    
    # X posts + arXiv papersã‚’è¿½åŠ 
    try:
        x_posts = fetch_x_posts()
        arxiv_papers = fetch_arxiv_papers()
        posts_items = x_posts + arxiv_papers
        
        # Posts categoryã§ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆ
        for item in posts_items:
            item['category'] = 'Posts'
        posts_items.sort(key=lambda x: x['score'], reverse=True)
        
        all_items.extend(posts_items[:MAX_ITEMS_PER_CATEGORY])
        print(f"âœ… X posts: {len(x_posts)}ä»¶, arXiv papers: {len(arxiv_papers)}ä»¶")
    except Exception as e:
        print(f"âŒ Postså–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    
    # å…¨ä½“ã§ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆ
    all_items.sort(key=lambda x: x['score'], reverse=True)
    
    print(f"ğŸ“Š ç·è¨˜äº‹æ•°: {len(all_items)}ä»¶")
    high_priority = len([x for x in all_items if x['score'] >= 4.0])
    medium_priority = len([x for x in all_items if x['score'] >= 2.5])
    print(f"ğŸ”¥ é«˜å„ªå…ˆåº¦: {high_priority}ä»¶")
    print(f"ğŸ“– ä¸­å„ªå…ˆåº¦: {medium_priority}ä»¶")
    
    return all_items

def fetch_x_posts():
    """X postsã‚’å–å¾—ï¼ˆç°¡ç´ ç‰ˆï¼‰"""
    if not X_POSTS_CSV:
        return []
        
    posts = []
    try:
        # Enhanced X ProcessorãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        try:
            from enhanced_x_processor import EnhancedXProcessor
            processor = EnhancedXProcessor()
            raw_posts = processor.process_x_posts(X_POSTS_CSV, max_posts=15)
            enhanced_posts = processor.convert_to_build_format(raw_posts)
            
            for post in enhanced_posts:
                item = {
                    'title': post.get('title', ''),
                    'summary': post.get('_summary', ''),
                    'url': post.get('link', ''),
                    'published': post.get('_dt', datetime.now(timezone.utc)),
                    'source': 'X (Twitter)',
                    'category': 'Posts',
                    'is_x_post': True
                }
                
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚³ã‚¢è¨ˆç®—
                item['score'] = SimpleEngineerRanking.calculate_score(item)
                icon, cls, text = SimpleEngineerRanking.get_priority(item['score'])
                item['priority_icon'] = icon
                item['priority_class'] = cls
                item['priority_text'] = text
                
                posts.append(item)
                
        except ImportError:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            response = requests.get(X_POSTS_CSV, timeout=10)
            response.encoding = 'utf-8'
            
            reader = csv.DictReader(io.StringIO(response.text))
            for i, row in enumerate(reader):
                if i >= 15:  # æœ€å¤§15ä»¶
                    break
                    
                if not row.get('content'):
                    continue
                    
                item = {
                    'title': (row.get('content', '') or '')[:100] + '...',
                    'summary': row.get('content', ''),
                    'url': row.get('url', ''),
                    'published': datetime.now(timezone.utc),
                    'source': 'X (Twitter)',
                    'category': 'Posts',
                    'is_x_post': True
                }
                
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚³ã‚¢è¨ˆç®—
                item['score'] = SimpleEngineerRanking.calculate_score(item)
                icon, cls, text = SimpleEngineerRanking.get_priority(item['score'])
                item['priority_icon'] = icon
                item['priority_class'] = cls
                item['priority_text'] = text
                
                posts.append(item)
            
    except Exception as e:
        print(f"X postså–å¾—å¤±æ•—: {e}")
        
    return posts

def fetch_arxiv_papers():
    """arXivè«–æ–‡ã‚’å–å¾—ï¼ˆAI/MLé–¢é€£ï¼‰"""
    papers = []
    arxiv_feeds = [
        'https://arxiv.org/rss/cs.AI',  # Artificial Intelligence
        'https://arxiv.org/rss/cs.LG',  # Machine Learning
        'https://arxiv.org/rss/cs.CL',  # Computation and Language
        'https://arxiv.org/rss/cs.CV',  # Computer Vision
    ]
    
    try:
        for feed_url in arxiv_feeds:
            try:
                print(f"  ğŸ”„ arXiv: {feed_url}")
                feed = feedparser.parse(feed_url)
                
                for entry in feed.entries[:5]:  # æœ€å¤§5ä»¶/ãƒ•ã‚£ãƒ¼ãƒ‰
                    pub_date = datetime.now(timezone.utc)
                    if hasattr(entry, 'published_parsed') and entry.published_parsed:
                        pub_date = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
                    
                    # 24æ™‚é–“ä»¥å†…ã®è«–æ–‡ã®ã¿
                    cutoff_time = datetime.now(timezone.utc) - timedelta(hours=HOURS_LOOKBACK)
                    if pub_date < cutoff_time:
                        continue
                    
                    item = {
                        'title': entry.get('title', 'No title'),
                        'url': entry.get('link', ''),
                        'summary': clean_text(entry.get('summary', '')),
                        'published': pub_date,
                        'source': 'arXiv',
                        'category': 'Posts',
                        'is_x_post': False
                    }
                    
                    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆç ”ç©¶è«–æ–‡ãªã®ã§+1.2å€ãƒœãƒ¼ãƒŠã‚¹ï¼‰
                    base_score = SimpleEngineerRanking.calculate_score(item)
                    item['score'] = min(base_score * 1.2, 10.0)  # ç ”ç©¶è«–æ–‡ãƒœãƒ¼ãƒŠã‚¹
                    icon, cls, text = SimpleEngineerRanking.get_priority(item['score'])
                    item['priority_icon'] = icon
                    item['priority_class'] = cls
                    item['priority_text'] = text
                    
                    papers.append(item)
                    
            except Exception as e:
                print(f"    âŒ arXivå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                
    except Exception as e:
        print(f"arXiv feedså‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
    return papers

def translate_items(items):
    """è¦ç´„ã‚’ç¿»è¨³ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
    if not TRANSLATE_AVAILABLE or not TRANSLATE_TO_JA:
        return
        
    cache_file = Path('_cache/translations.json')
    cache_file.parent.mkdir(exist_ok=True)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿
    cache = {}
    if cache_file.exists():
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
        except:
            cache = {}
    
    # ç¿»è¨³ã‚¨ãƒ³ã‚¸ãƒ³
    translator = GoogleTranslator(source='en', target='ja')
    translated = 0
    
    for item in items:
        summary = item.get('summary', '')
        if len(summary) < 10:
            continue
            
        cache_key = f"google:{hash(summary)}"
        
        if cache_key in cache:
            item['summary'] = cache[cache_key]
        else:
            try:
                translated_text = translator.translate(summary)
                item['summary'] = translated_text
                cache[cache_key] = translated_text
                translated += 1
                
                if translated % 5 == 0:
                    time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™
                    
            except Exception as e:
                print(f"ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
    try:
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"ğŸ”¤ æ–°è¦ç¿»è¨³: {translated}ä»¶")

def generate_html(items):
    """HTMLç”Ÿæˆ"""
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡ï¼ˆã‚¹ã‚³ã‚¢é †ç¶­æŒï¼‰
    categories = {}
    for item in items:
        cat = item['category']
        if cat not in categories:
            categories[cat] = []
        categories[cat].append(item)
    
    # çµ±è¨ˆ
    total = len(items)
    hot = len([x for x in items if x['score'] >= 6.0])
    high = len([x for x in items if x['score'] >= 4.0 and x['score'] < 6.0])
    medium = len([x for x in items if x['score'] >= 2.5 and x['score'] < 4.0])
    
    now = datetime.now().strftime("%Y-%m-%d %H:%M JST")
    
    html = f'''<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Daily AI News â€” {now}</title>
  <link rel="stylesheet" href="style.css"/>
</head>
<body>
  <header class="site-header">
    <div class="brand">ğŸ“° Daily AI News</div>
    <div class="updated">æœ€çµ‚æ›´æ–°ï¼š{now}</div>
  </header>

  <main class="container">
    <h1 class="page-title">ä»Šæ—¥ã®æœ€æ–°AIæƒ…å ±</h1>
    <p class="lead">
        ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤ºã€‚å®Ÿè£…å¯èƒ½æ€§ãƒ»æŠ€è¡“çš„ä¾¡å€¤ãƒ»å­¦ç¿’åŠ¹æœã‚’é‡è¦–ã—ãŸè‡ªå‹•ã‚½ãƒ¼ãƒˆã€‚
        è±Šå¯Œãªæƒ…å ±é‡ï¼ˆ{total}ä»¶ï¼‰ã‚’ç¶­æŒã—ã¤ã¤ã€é‡è¦åº¦ã§æ•´ç†è¡¨ç¤ºã€‚
    </p>

    <section class="kpi-grid">
      <div class="kpi-card">
        <div class="kpi-value">{total}ä»¶</div>
        <div class="kpi-label">ç·è¨˜äº‹æ•°</div>
        <div class="kpi-note">æƒ…å ±é‡ç¶­æŒ</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-value">{hot + high}ä»¶</div>
        <div class="kpi-label">é«˜å„ªå…ˆåº¦è¨˜äº‹</div>
        <div class="kpi-note">ã‚¹ã‚³ã‚¢4.0ä»¥ä¸Š</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-value">{medium}ä»¶</div>
        <div class="kpi-label">ä¸­å„ªå…ˆåº¦è¨˜äº‹</div>
        <div class="kpi-note">ã‚¹ã‚³ã‚¢2.5ä»¥ä¸Š</div>
      </div>
      <div class="kpi-card">
        <div class="kpi-value">{now}</div>
        <div class="kpi-label">æœ€çµ‚æ›´æ–°</div>
        <div class="kpi-note">è‡ªå‹•æ›´æ–°</div>
      </div>
    </section>
    
    <div class="filter-controls">
      <div class="filter-group">
        <label>å„ªå…ˆåº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼:</label>
        <button class="filter-btn active" data-filter="all">ã™ã¹ã¦ ({total})</button>
        <button class="filter-btn" data-filter="hot">ğŸ”¥ æœ€é«˜å„ªå…ˆ ({hot})</button>
        <button class="filter-btn" data-filter="high">âš¡ é«˜å„ªå…ˆ ({high})</button>
        <button class="filter-btn" data-filter="medium">ğŸ“– ä¸­å„ªå…ˆ ({medium})</button>
      </div>
      <div class="search-container">
        <input id="searchBox" type="text" placeholder="ğŸ” æŠ€è¡“ã€ä¼æ¥­ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢..." />
      </div>
    </div>

    <nav class="tabs" role="tablist">'''
    
    # ã‚¿ãƒ–ç”Ÿæˆ
    for i, (cat, cat_items) in enumerate(categories.items()):
        active = 'active' if i == 0 else ''
        icon = get_category_icon(cat)
        html += f'''
      <button class="tab {active}" data-target="#{cat.lower()}" aria-selected="{str(i==0).lower()}">
        {icon} {cat} ({len(cat_items)})
      </button>'''
    
    html += '''
    </nav>

'''
    
    # ã‚¿ãƒ–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    for i, (cat, cat_items) in enumerate(categories.items()):
        active = 'active' if i == 0 else ''
        html += f'''    <section id="{cat.lower()}" class="tab-panel {active}">
'''
        
        for item in cat_items:
            html += generate_card_html(item)
        
        html += '''    </section>

'''
    
    html += '''  </main>

  <footer class="site-footer">
    <div class="footer-content">
      <p>Â© 2025 Daily AI News - Enhanced with Simple Engineer Ranking</p>
      <p>æƒ…å ±é‡ã‚’ç¶­æŒã—ã¤ã¤ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’å®Ÿç¾</p>
    </div>
  </footer>

  <script>
    // ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½
    document.addEventListener('DOMContentLoaded', function() {
      const tabs = document.querySelectorAll('.tab');
      const panels = document.querySelectorAll('.tab-panel');
      
      tabs.forEach(tab => {
        tab.addEventListener('click', function() {
          // ã™ã¹ã¦ã®ã‚¿ãƒ–ã¨ãƒ‘ãƒãƒ«ã‚’ãƒªã‚»ãƒƒãƒˆ
          tabs.forEach(t => {
            t.classList.remove('active');
            t.setAttribute('aria-selected', 'false');
          });
          panels.forEach(p => {
            p.classList.remove('active');
          });
          
          // ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã‚¿ãƒ–ã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«
          this.classList.add('active');
          this.setAttribute('aria-selected', 'true');
          
          // å¯¾å¿œã™ã‚‹ãƒ‘ãƒãƒ«ã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«
          const targetId = this.getAttribute('data-target');
          const targetPanel = document.querySelector(targetId);
          if (targetPanel) {
            targetPanel.classList.add('active');
          }
        });
      });
      
      // ãƒ•ã‚£ãƒ«ã‚¿æ©Ÿèƒ½
      const searchBox = document.getElementById('searchBox');
      const filterBtns = document.querySelectorAll('.filter-btn');
      
      if (searchBox) {
        searchBox.addEventListener('input', function() {
          filterCards();
        });
      }
      
      filterBtns.forEach(btn => {
        btn.addEventListener('click', function() {
          filterBtns.forEach(b => b.classList.remove('active'));
          this.classList.add('active');
          filterCards();
        });
      });
      
      function filterCards() {
        const query = searchBox ? searchBox.value.toLowerCase() : '';
        const activeFilter = document.querySelector('.filter-btn.active');
        const filterType = activeFilter ? activeFilter.getAttribute('data-filter') : 'all';
        const activePanel = document.querySelector('.tab-panel.active');
        
        if (activePanel) {
          const cards = activePanel.querySelectorAll('.card');
          cards.forEach(card => {
            const title = card.querySelector('.card-title');
            const summary = card.querySelector('.card-summary');
            const titleText = title ? title.textContent.toLowerCase() : '';
            const summaryText = summary ? summary.textContent.toLowerCase() : '';
            
            const matchesSearch = !query || titleText.includes(query) || summaryText.includes(query);
            
            let matchesFilter = true;
            if (filterType !== 'all') {
              const priority = card.getAttribute('data-priority') || '';
              matchesFilter = priority === filterType;
            }
            
            if (matchesSearch && matchesFilter) {
              card.style.display = '';
            } else {
              card.style.display = 'none';
            }
          });
        }
      }
    });
  </script>
</body>
</html>'''
    
    return html

def generate_card_html(item):
    """è¨˜äº‹ã‚«ãƒ¼ãƒ‰HTMLç”Ÿæˆï¼ˆSNS/è«–æ–‡å¯¾å¿œï¼‰"""
    time_ago = format_time_ago(item.get('published', datetime.now(timezone.utc)))
    
    # è¦ç´„ã‚’é©åˆ‡ãªé•·ã•ã«èª¿æ•´
    summary = item.get('summary', '')
    if len(summary) > 200:
        summary = summary[:197] + '...'
    
    # Postsï¼ˆSNS/è«–æ–‡ï¼‰ç‰¹æœ‰ã®è¡¨ç¤º
    post_type_indicator = ""
    if item.get('category') == 'Posts':
        if item.get('is_x_post', False):
            post_type_indicator = '<span class="post-type-badge twitter">ğŸ¦ Twitter</span>'
        elif 'arxiv' in item.get('source', '').lower():
            post_type_indicator = '<span class="post-type-badge arxiv">ğŸ“‘ arXiv</span>'
    
    return f'''
<article class="card enhanced-card" data-score="{item.get('score', 0):.1f}" data-priority="{item.get('priority_class', 'minimal')}">
  <div class="card-header">
    <div class="priority-indicator {item.get('priority_class', 'minimal')}">
      <span class="priority-icon">{item.get('priority_icon', 'ğŸ“„')}</span>
      <span class="priority-text">{item.get('priority_text', 'å‚è€ƒ')}</span>
      <span class="score-badge">ã‚¹ã‚³ã‚¢: {item.get('score', 0):.1f}</span>
    </div>
    <div class="card-meta">
      <span class="meta-time">ğŸ“… {time_ago}</span>
      <span class="meta-source">ğŸ“– {item.get('source', '')}</span>
      {post_type_indicator}
    </div>
  </div>
  
  <div class="card-body">
    <a class="card-title" href="{item.get('url', '')}" target="_blank" rel="noopener">
      {item.get('title', 'No title')}
    </a>
    <p class="card-summary">{summary}</p>
  </div>
  
  <div class="card-footer">
    <div class="card-actions">
      <a href="{item.get('url', '')}" class="action-btn primary" target="_blank">ğŸ“– è©³ç´°ã‚’èª­ã‚€</a>
      <button class="action-btn bookmark" data-url="{item.get('url', '')}">ğŸ”– ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯</button>
    </div>
  </div>
</article>
'''

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def clean_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°"""
    if not text:
        return ''
    text = re.sub(r'<[^>]+>', '', text)
    text = html.unescape(text)
    return text.strip()

def get_source_name(url):
    """URLã‹ã‚‰ã‚½ãƒ¼ã‚¹åæŠ½å‡º"""
    domain = urlparse(url).netloc
    return domain.replace('www.', '').replace('.com', '').replace('.org', '').title()

def get_category_icon(category):
    """ã‚«ãƒ†ã‚´ãƒªã‚¢ã‚¤ã‚³ãƒ³"""
    icons = {
        'Business': 'ğŸ¢', 
        'Tools': 'âš¡', 
        'Posts': 'ğŸ§ª'  # SNS/è«–æ–‡ãƒã‚¹ãƒˆ
    }
    return icons.get(category, 'ğŸ“„')

def format_time_ago(dt):
    """ç›¸å¯¾æ™‚é–“è¡¨ç¤º"""
    if not dt:
        return "ä¸æ˜"
    diff = datetime.now(timezone.utc) - dt
    hours = int(diff.total_seconds() / 3600)
    if hours < 1:
        return "ä»Š"
    elif hours < 24:
        return f"{hours}æ™‚é–“å‰"
    else:
        return f"{hours // 24}æ—¥å‰"

def generate_css():
    """CSSãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    css_content = '''/* Digital.gov compliance deployed at 2025-08-20 23:07:20 JST */
:root{
  /* Digital.govæº–æ‹ : WCAG AAAå¯¾å¿œã‚«ãƒ©ãƒ¼ã‚·ã‚¹ãƒ†ãƒ  */
  --fg:#0f172a; --bg:#ffffff; --muted:#475569; --line:#e2e8f0;
  --brand:#1e40af; --brand-weak:#f1f5f9; --chip:#f8fafc;
  --brand-hover:#1e3a8a; --brand-light:#bfdbfe; --brand-dark:#1e3a8a;
  --success:#15803d; --warning:#ca8a04; --danger:#dc2626;
  --info:#0369a1; --neutral:#64748b;
  
  /* æ®µéšçš„èƒŒæ™¯è‰²ï¼ˆå½©åº¦ã‚’ä¸‹ã’ãŸèƒŒæ™¯ï¼‰ */
  --bg-subtle:#f8fafc; --bg-muted:#f1f5f9; --bg-emphasis:#e2e8f0;
  
  /* ã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå½©åº¦èª¿æ•´æ¸ˆã¿ï¼‰ */
  --gradient:linear-gradient(135deg, #1e40af 0%, #1e3a8a 100%);
  --gradient-subtle:linear-gradient(135deg, #f1f5f9 0%, #e2e8f0 100%);
  
  /* ã‚·ãƒ£ãƒ‰ã‚¦ */
  --shadow:0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
  --shadow-lg:0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
  
  /* ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¤‰æ•° */
  --border-radius: 12px;
  --spacing-xs: 4px; --spacing-sm: 8px; --spacing-md: 16px; 
  --spacing-lg: 24px; --spacing-xl: 32px; --spacing-2xl: 48px;
  
  /* ã‚¿ã‚¤ãƒã‚°ãƒ©ãƒ•ã‚£ */
  --font-size-xs: 12px; --font-size-sm: 14px; --font-size-base: 16px;
  --font-size-lg: 18px; --font-size-xl: 20px; --font-size-2xl: 24px;
  --font-size-3xl: 32px; --font-size-4xl: 36px;
  
  /* ãƒ•ã‚©ãƒ¼ã‚«ã‚¹è¡¨ç¤º */
  --focus-ring: 0 0 0 3px rgba(59, 130, 246, 0.5);
  --focus-ring-offset: 2px;
}
*{box-sizing:border-box}
body{
  margin:0;
  background:var(--bg);
  color:var(--fg);
  font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial,'Noto Sans JP',sans-serif;
  font-size:var(--font-size-base);
  line-height:1.6;
  scroll-behavior:smooth;
}
.container{
  max-width:1000px;
  margin:0 auto;
  padding:var(--spacing-lg) var(--spacing-md);
  display:flex;
  flex-direction:column;
  gap:var(--spacing-lg);
}

/* ãƒ˜ãƒƒãƒ€ãƒ¼ */
.site-header{
  display:flex;
  justify-content:space-between;
  align-items:center;
  padding:var(--spacing-md);
  background:var(--bg-subtle);
  border-bottom:1px solid var(--line);
  margin-bottom:var(--spacing-lg);
}
.brand{
  font-size:var(--font-size-xl);
  font-weight:700;
  color:var(--brand);
}
.updated{
  color:var(--muted);
  font-size:var(--font-size-sm);
}

/* ã‚¿ã‚¤ãƒˆãƒ« */
.page-title{
  font-size:var(--font-size-3xl);
  font-weight:700;
  margin:0 0 var(--spacing-md) 0;
  text-align:center;
  background:var(--gradient);
  -webkit-background-clip:text;
  -webkit-text-fill-color:transparent;
  background-clip:text;
}
.lead{
  font-size:var(--font-size-lg);
  color:var(--muted);
  text-align:center;
  margin-bottom:var(--spacing-xl);
  line-height:1.7;
}

/* KPI Grid */
.kpi-grid{
  display:grid;
  grid-template-columns:repeat(auto-fit, minmax(200px, 1fr));
  gap:var(--spacing-md);
  margin-bottom:var(--spacing-xl);
}
.kpi-card{
  background:var(--bg-subtle);
  padding:var(--spacing-md);
  border-radius:var(--border-radius);
  text-align:center;
  border:1px solid var(--line);
}
.kpi-value{
  font-size:var(--font-size-2xl);
  font-weight:700;
  color:var(--brand);
}
.kpi-label{
  font-size:var(--font-size-sm);
  color:var(--muted);
  margin-top:var(--spacing-xs);
}
.kpi-note{
  font-size:var(--font-size-xs);
  color:var(--neutral);
  margin-top:var(--spacing-xs);
}

/* ã‚¿ãƒ– */
.tabs{
  display:flex;
  border-bottom:2px solid var(--line);
  margin-bottom:var(--spacing-lg);
  gap:var(--spacing-sm);
}
.tab{
  background:none;
  border:none;
  padding:var(--spacing-md) var(--spacing-lg);
  font-size:var(--font-size-base);
  cursor:pointer;
  border-bottom:3px solid transparent;
  transition:all 0.3s ease;
  color:var(--muted);
}
.tab.active{
  color:var(--brand);
  border-bottom-color:var(--brand);
  font-weight:600;
}
.tab:hover{
  color:var(--brand-hover);
  background:var(--bg-subtle);
  border-radius:var(--border-radius) var(--border-radius) 0 0;
}

/* ã‚¿ãƒ–ãƒ‘ãƒãƒ« */
.tab-panel{
  display:block;
}
.tab-panel.hidden{
  display:none;
}

/* æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ */
.search-container{
  margin-bottom:var(--spacing-lg);
}
.search-header{
  display:flex;
  flex-direction:column;
  gap:var(--spacing-sm);
  margin-bottom:var(--spacing-md);
}
#searchBox{
  padding:var(--spacing-md);
  border:1px solid var(--line);
  border-radius:var(--border-radius);
  font-size:var(--font-size-base);
  width:100%;
}
#searchBox:focus{
  outline:none;
  border-color:var(--brand);
  box-shadow:var(--focus-ring);
}
.search-info{
  font-size:var(--font-size-sm);
  color:var(--muted);
  text-align:center;
}
.filter-controls{
  display:flex;
  gap:var(--spacing-sm);
  flex-wrap:wrap;
}
.filter-controls select{
  padding:var(--spacing-sm) var(--spacing-md);
  border:1px solid var(--line);
  border-radius:var(--border-radius);
  background:var(--bg);
}

/* ã‚«ãƒ¼ãƒ‰ */
.card{
  background:var(--bg);
  border:1px solid var(--line);
  border-radius:var(--border-radius);
  margin-bottom:var(--spacing-md);
  overflow:hidden;
  box-shadow:var(--shadow);
  transition:all 0.3s ease;
}
.card:hover{
  box-shadow:var(--shadow-lg);
  transform:translateY(-2px);
}
.card-header{
  padding:var(--spacing-md);
  background:var(--bg-subtle);
  border-bottom:1px solid var(--line);
}
.card-title{
  font-size:var(--font-size-lg);
  font-weight:600;
  color:var(--brand);
  text-decoration:none;
  display:block;
  line-height:1.4;
}
.card-title:hover{
  color:var(--brand-hover);
  text-decoration:underline;
}
.card-body{
  padding:var(--spacing-md);
}
.card-summary{
  color:var(--fg);
  line-height:1.6;
  margin:0 0 var(--spacing-md) 0;
}
.card-footer{
  padding:var(--spacing-md);
  background:var(--bg-muted);
  border-top:1px solid var(--line);
  font-size:var(--font-size-sm);
  color:var(--muted);
}
.card-footer a{
  color:var(--brand);
  text-decoration:none;
}
.card-footer a:hover{
  text-decoration:underline;
}

/* ãƒãƒƒãƒ— */
.chips{
  display:flex;
  gap:var(--spacing-sm);
  flex-wrap:wrap;
}
.chip{
  background:var(--chip);
  color:var(--brand);
  padding:var(--spacing-xs) var(--spacing-sm);
  border-radius:var(--border-radius);
  font-size:var(--font-size-xs);
  border:1px solid var(--line);
}
.chip.ghost{
  background:transparent;
  color:var(--muted);
}

/* ãƒ•ãƒƒã‚¿ãƒ¼ */
.site-footer{
  margin-top:var(--spacing-2xl);
  padding:var(--spacing-lg);
  background:var(--bg-subtle);
  border-top:1px solid var(--line);
  text-align:center;
  font-size:var(--font-size-sm);
  color:var(--muted);
}
.site-footer a{
  color:var(--brand);
  text-decoration:none;
}
.site-footer a:hover{
  text-decoration:underline;
}

/* ãƒãƒ¼ãƒˆ */
.note{
  background:var(--bg-emphasis);
  border:1px solid var(--line);
  border-radius:var(--border-radius);
  padding:var(--spacing-md);
  margin-top:var(--spacing-xl);
  font-size:var(--font-size-sm);
  color:var(--muted);
  text-align:center;
}

/* ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ– */
@media (max-width: 768px) {
  .container{
    padding:var(--spacing-md) var(--spacing-sm);
  }
  .site-header{
    flex-direction:column;
    gap:var(--spacing-sm);
    text-align:center;
  }
  .tabs{
    flex-direction:column;
  }
  .tab{
    border-bottom:none;
    border-left:3px solid transparent;
  }
  .tab.active{
    border-left-color:var(--brand);
    background:var(--bg-subtle);
  }
  .kpi-grid{
    grid-template-columns:1fr;
  }
  .filter-controls{
    flex-direction:column;
  }
  .chips{
    justify-content:center;
  }
}

/* ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ */
.tab:focus{
  outline:none;
  box-shadow:var(--focus-ring);
}
#searchBox:focus{
  outline:none;
  box-shadow:var(--focus-ring);
}
.card-title:focus{
  outline:none;
  box-shadow:var(--focus-ring);
}'''
    
    return css_content

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ Simple Enhanced Daily AI News")
    print("=" * 40)
    print(f"âš™ï¸ {HOURS_LOOKBACK}æ™‚é–“ã€æœ€å¤§{MAX_ITEMS_PER_CATEGORY}ä»¶/ã‚«ãƒ†ã‚´ãƒª")
    
    # è¨˜äº‹å–å¾—
    items = fetch_articles()
    
    # ç¿»è¨³
    translate_items(items)
    
    # HTMLç”Ÿæˆ
    html_content = generate_html(items)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    output_file = Path('index.html')
    output_file.write_text(html_content, encoding='utf-8')
    
    # CSSç”Ÿæˆ
    css_content = generate_css()
    css_file = Path('style.css')
    css_file.write_text(css_content, encoding='utf-8')
    print("âœ… CSS file generated")
    
    print(f"âœ… ç”Ÿæˆå®Œäº†: {output_file}")
    print("ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°å®Œäº†")

if __name__ == "__main__":
    main()